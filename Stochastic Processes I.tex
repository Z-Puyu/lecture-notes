\documentclass[math, code]{amznotes}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
%\usepackage{yhmath}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{etoolbox}
\DeclareSymbolFont{yhlargesymbols}{OMX}{yhex}{m}{n} \DeclareMathAccent{\yhwidehat}{\mathord}{yhlargesymbols}{"62}

\usepackage{scalerel}[2014/03/10]
\usepackage{stackengine}

\renewcommand\widetilde[1]{\ThisStyle{%
  \setbox0=\hbox{$\SavedStyle#1$}%
  \stackengine{1pt-\LMpt}{$\SavedStyle#1$}{%
    \stretchto{\scaleto{\SavedStyle\mkern.2mu\sim}{.5467\wd0}}{.5\ht0}%
%    .2mu is the kern imbalance when clipping white space
%    .5467++++ is \ht/[kerned \wd] aspect ratio for \sim glyph
  }{O}{c}{F}{T}{S}%
}}
\makeatletter
\let\save@mathaccent\mathaccent
\newcommand*\if@single[3]{%
  \setbox0\hbox{${\mathaccent"0362{#1}}^H$}%
  \setbox2\hbox{${\mathaccent"0362{\kern0pt#1}}^H$}%
  \ifdim\ht0=\ht2 #3\else #2\fi
  }
%The bar will be moved to the right by a half of \macc@kerna, which is computed by amsmath:
\newcommand*\rel@kern[1]{\kern#1\dimexpr\macc@kerna}
%If there's a superscript following the bar, then no negative kern may follow the bar;
%an additional {} makes sure that the superscript is high enough in this case:
\newcommand*\widebar[1]{\@ifnextchar^{{\wide@bar{#1}{0}}}{\wide@bar{#1}{1}}}
%Use a separate algorithm for single symbols:
\newcommand*\wide@bar[2]{\if@single{#1}{\wide@bar@{#1}{#2}{1}}{\wide@bar@{#1}{#2}{2}}}
\newcommand*\wide@bar@[3]{%
  \begingroup
  \def\mathaccent##1##2{%
%Enable nesting of accents:
    \let\mathaccent\save@mathaccent
%If there's more than a single symbol, use the first character instead \left(see below\right):
    \if#32 \let\macc@nucleus\first@char \fi
%Determine the italic correction:
    \setbox\z@\hbox{$\macc@style{\macc@nucleus}_{}$}%
    \setbox\tw@\hbox{$\macc@style{\macc@nucleus}{}_{}$}%
    \dimen@\wd\tw@
    \advance\dimen@-\wd\z@
%Now \dimen@ is the italic correction of the symbol.
    \divide\dimen@ 3
    \@tempdima\wd\tw@
    \advance\@tempdima-\scriptspace
%Now \@tempdima is the width of the symbol.
    \divide\@tempdima 10
    \advance\dimen@-\@tempdima
%Now \dimen@ = \left(italic correction / 3\right) - \left(Breite / 10\right)
    \ifdim\dimen@>\z@ \dimen@0pt\fi
%The bar will be shortened in the case \dimen@<0 !
    \rel@kern{0.6}\kern-\dimen@
    \if#31
      \overline{\rel@kern{-0.6}\kern\dimen@\macc@nucleus\rel@kern{0.4}\kern\dimen@}%
      \advance\dimen@0.4\dimexpr\macc@kerna
%Place the combined final kern \left(-\dimen@\right) if it is >0 or if a superscript follows:
      \let\final@kern#2%
      \ifdim\dimen@<\z@ \let\final@kern1\fi
      \if\final@kern1 \kern-\dimen@\fi
    \else
      \overline{\rel@kern{-0.6}\kern\dimen@#1}%
    \fi
  }%
  \macc@depth\@ne
  \let\math@bgroup\@empty \let\math@egroup\macc@set@skewchar
  \mathsurround\z@ \frozen@everymath{\mathgroup\macc@group\relax}%
  \macc@set@skewchar\relax
  \let\mathaccentV\macc@nested@a
%The following initialises \macc@kerna and calls \mathaccent:
  \if#31
    \macc@nested@a\relax111{#1}%
  \else
%If the argument consists of more than one symbol, and if the first token is
%a letter, use that letter for the computations:
    \def\gobble@till@marker##1\endmarker{}%
    \futurelet\first@char\gobble@till@marker#1\endmarker
    \ifcat\noexpand\first@char A\else
      \def\first@char{}%
    \fi
    \macc@nested@a\relax111{\first@char}%
  \fi
  \endgroup
}
\makeatother

\graphicspath{ {./images/} }
\geometry{
    a4paper,
    headheight = 1.5cm
}

\patchcmd{\chapter}{\thispagestyle{plain}}
{\thispagestyle{fancy}}{}{}

\theoremstyle{remark}
\newtheorem*{claim}{Claim}
\newtheorem*{remark}{Remark}
\newtheorem{case}{Case}

\newcommand{\zero}{\mathbf{0}}
\newcommand{\one}{\mathbf{1}}
\newcommand{\I}{\mathbfit{I}}
\newcommand{\e}{\mathrm{e}}
\renewcommand{\d}{\mathrm{d}}
\newcommand{\im}{\mathrm{i}}
\newcommand{\map}[3]{#1: #2 \rightarrow #3} % Mapping
\newcommand{\image}[2]{#2\left[#1\right]} % Image
\newcommand{\preimage}[2]{#2\left[#1\right]^{-1}} % Pre-image
\newcommand{\eval}[3]{\left. #1\right\rvert_{#2 = #3}} % Evaluated at
%\newcommand\bigO[1]{\mathcal{O}\left(#1\right)}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathAlphabet{\mathcal}{OMS}{cmsy}{m}{n}

\begin{document}
\fancyhead[L]{
    Stochastic Processes I
}
\fancyhead[R]{
    Lecture Notes
}
\tableofcontents

\chapter{Probability}
\chapter{Markov Chains}
\section{Markov Chains}
\begin{dfnbox}{Stochastic Process}{stochastic}
    A {\color{red} \textbf{stochastic process}} is a collection of random variables $\left\{X\left(t\right) \colon t \in T\right\}$ where $T$ is an {\color{red} \textbf{index set}} and $X\left(t\right)$ is known as the {\color{red} \textbf{current state}}. The set of all possible states is known as the {\color{red} \textbf{state space}}.
\end{dfnbox}
Let $\Omega$ be a sample space, a stochastic process defined over the space can be thought of a sequence of random variables where $X\left(t\right)$ describes the distribution of an outcome $\omega \in \Omega$ at timestamp $t$. The state space $S$ is simply the co-domain of the $X\left(t\right)$'s.

A stochastic process is said to be 
\begin{itemize}
    \item \textit{discrete-time} if the index set is countable;
    \item \textit{continuous-time} if the index set is a continuum;
    \item \textit{discrete-state} if the state space is countable;
    \item \textit{finite-state} if the state space is finite;
    \item \textit{continuous-state} if the state space is a continuum.
\end{itemize}
The term ``continuum'' refers to a \textbf{non-empty compact connected metric space}. 

In this course, we focus on discrete-time discrete-state stochastic processes. One important property we will discuss now is the \textit{Markovian property}.
\begin{dfnbox}{Markovian Property}{markovian}
    Let $\left\{X_n \colon n \in T\right\}$ be a discrete-time stochastic process over some probability space~$\left(\Omega, \mathcal{F}, P\right)$. The stochastic process is called {\color{red} \textbf{Markovian}} if 
    \begin{equation*}
        P\bigl(X_{n + 1} = x_{n + 1} \mid X_0^n = \left(x_0, x_1, \cdots, x_n\right)\bigr) = P\left(X_{n + 1} = x_{n + 1} \mid X_n = x_n\right)
    \end{equation*}
    for all $n \in \N$.
\end{dfnbox}
The Markovian property essentially says that, given $X_n$, what has happened before, i.e., $X_k$ for all $k < n$, is independent of what happens afterwards, i.e., $X_{n + m}$ for $m \in \N^+$.

As the name suggests, the Markovian property is closely related to the Markov chains, which can be defined rigorously as follows:
\begin{dfnbox}{Discrete-Time Markov Chain}{MarkovChain}
    A {\color{red} \textbf{Markov chain}} is a discrete-time discrete-state stochastic process satisfying the Markovian property.
\end{dfnbox}
Recall that the \textit{Bayes's Theorem} states the following:
\begin{thmbox}{Bayes's Theorem}{Bayes}
    For any random variables $X$ and $Y$, 
    \begin{equation*}
        p_{X \mid Y}\left(x \mid y\right) = \frac{p_{Y \mid X}\left(y \mid x\right)p_X\left(x\right)}{\sum_{x' \in \mathcal{X}}p_{Y \mid X}\left(y \mid x'\right)p_X\left(x'\right)}.
    \end{equation*}
\end{thmbox}
Theorem \ref{thm:Bayes} leads to the following important result:
\begin{corbox}{Bayes' Rule for Markov Chains}{MarkovBayes}
    Let $X_1, X_2, \cdots, X_n$ be any $n$ random variables forming a Markov chain, then 
    \begin{equation*}
        p_{X_1^n}\left(x_1, x_2, \cdots, x_n\right) = p_{X_1}\left(x_1\right)\prod_{i = 1}^{n - 1}p_{X_{i + 1} \mid X_i}\left(x_{i + 1} \mid x_i\right).
    \end{equation*}
    \tcblower
    \begin{proof}
        If $n = 2$, by Theorem \ref{thm:Bayes}, we know that 
        \begin{align*}
            p_{X_1, X_2}\left(x_1, x_2\right) & = p_{X_1 \mid X_2}\left(x_1 \mid x_2\right)p_{X_2}\left(x_2\right) \\
            & = p_{X_1}\left(x_1\right)p_{X_2 \mid X_1}\left(x_2 \mid x_1\right).
        \end{align*}
        Suppose that there exists some integer $k \geq 2$ such that 
        \begin{equation*}
            p_{X_1^k}\left(x_1, x_2, \cdots, x_k\right) = p_{X_1}\left(x_1\right)\prod_{i = 1}^{k - 1}p_{X_{i + 1} \mid X_i}\left(x_{i + 1} \mid x_i\right)
        \end{equation*}
        For any $k$ random variables $X_1^k$ forming a Markov chain. Let $X_{k + 1}$ be any random variable such that $X_1^{k + 1}$ forms a Markov chain, then 
        \begin{equation*}
            p_{X_{k + 1} \mid X_1^{k}}\left(x_{k + 1} \mid x_1, x_2, \cdots, x_k\right) = p_{X_{k + 1} \mid X_k}\left(x_{k + 1} \mid x_k\right).
        \end{equation*}
        By using Theorem \ref{thm:Bayes}, we have
        \begin{align*}
            p_{X_1^{k + 1}}\left(x_1, x_2, \cdots, x_{k + 1}\right) & = p_{X_{k + 1} \mid X_1^{k}}\left(x_{k + 1} \mid x_1, x_2, \cdots, x_k\right)p_{X_1^k}\left(x_1, x_2, \cdots, x_k\right) \\
            & = p_{X_{k + 1} \mid X_k}\left(x_{k + 1} \mid x_k\right)p_{X_1}\left(x_1\right)\prod_{i = 1}^{k - 1}p_{X_{i + 1} \mid X_i}\left(x_{i + 1} \mid x_i\right) \\
            & = p_{X_1}\left(x_1\right)\prod_{i = 1}^{k}p_{X_{i + 1} \mid X_i}\left(x_{i + 1} \mid x_i\right).
        \end{align*}
    \end{proof}
\end{corbox}
Consider a discrete-time discrete-state stochastic process $\left\{X_n \colon n \in T\right\}$ with state space $S$ over some probability space $\left(\Omega, \mathcal{F}, P\right)$. Here, the $\sigma$-algebra $\mathcal{F}$ can be generated using simple events $\left\{\omega \in \Omega \colon X_n\left(\omega\right) = s\right\}$ for all $n \in T$ and $s \in S$. Notice that this means that we need to find the joint distribution 
\begin{equation*}
    p_{X_{n_1}^{n_k}}\left(s_1, s_2, \cdots, s_k\right)
\end{equation*}
for any tuple of random variables $X_{n_1}^{n_k}$ in the stochastic process, where $k \in \N$ and $k \leq \abs{T}$ if $T$ is finite, and any $\left(s_1, s_2, \cdots, s_k\right) \in S^k$. In general, this joint distribution might be hard to find, but things become easier if the stochastic process is a Markov chain because by Corollary \ref{cor:MarkovBayes} we have
\begin{align*}
    p_{X_{n_1}^{n_k}}\left(s_1, s_2, \cdots, s_k\right) = p_{X_{n_1}}\left(s_1\right)\prod_{i = 1}^{k - 1}p_{X_{n_{i + 1}} \mid X_{n_i}}\left(s_{i + 1} \mid s_i\right).
\end{align*}
If we can find $p_{X_m \mid X_n}\left(s_m \mid s_n\right)$ for any $m > n$, we could simplify this expression further! 
\begin{dfnbox}{Transition Probability}{transProb}
    The {\color{red} \textbf{transition probability}} is defined as 
    \begin{equation*}
        p_{ij}^{n, m} \coloneqq P\left(X_{m} = j \mid X_n = i\right).
    \end{equation*}
    In particular, $p_{ij}^{n, n + 1}$ is known as the {\color{red} \textbf{one-step transition probability}} or {\color{red} \textbf{jump probability}}.
\end{dfnbox}
Take some $k \in \N^+$ and consider
\begin{align*}
    p_{ij}^{n, n + k} = P\left(X_{n + k} = j \mid X_n = i\right).
\end{align*}
We first marginalise $P\left(X_{n + k} = j \mid X_n = i\right)$ with respect to $X_{n + 1}$ to obtain
\begin{equation*}
    P\left(X_{n + k} = j \mid X_n = i\right) = \sum_{s \in S}P\left(X_{n + k} = j \mid X_n = i, X_{n + 1} = s\right)P\left(X_{n + 1} = s \mid X_n = i\right).
\end{equation*}
Since $X_n$, $X_{n + 1}$ and $X_{n + k}$ form a Markov chain, we have
\begin{equation*}
    P\left(X_{n + k} = j \mid X_n = i, X_{n + 1} = s\right) = P\left(X_{n + k} = j \mid X_{n + 1} = s\right).
\end{equation*}
Therefore, 
\begin{align*}
    p_{ij}^{n, n + k} & = P\left(X_{n + k} = j \mid X_n = i\right) \\
    & = \sum_{s \in S}P\left(X_{n + k} = j \mid X_{n + 1} = s\right)P\left(X_{n + 1} = s \mid X_n = i\right) \\
    & = \sum_{s \in S}p_{sj}^{n + 1, n + k}p_{is}^{n, n + 1}.
\end{align*}
Notice that now we have reduced the gap by $1$. By repeatedly applying this process to $p_{sj}^{n + 1, n + k}$, we eventually arrive at 
\begin{equation*}
    p_{ij}^{n, n + k} = \sum_{s_1, s_2, \cdots, s_{k - 1} \in S}p_{is_1}^{n, n + 1}\left(\prod_{r = 1}^{m - n - 2}p_{s_rs_{r + 1}}^{n + r, n + r + 1}\right)p_{s_{m - 1}j}^{n + k - 1, n + k}
\end{equation*}
It is useful to see the one-step transition probability $p_{ij}^{n, n + 1}$ as a function 
\begin{equation*}
    f \colon T \times S \times S \to \R.
\end{equation*}
Thus far, we have basically shown that to specify a Markov chain fully, we will need to define the \textbf{index set} $T$, the \textbf{state space} $S$ and the \textbf{one-step transition probabilities} $p_{ij}^{n, n + 1}$ for all $i, j \in S$.
\end{document}