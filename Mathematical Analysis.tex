\documentclass[math]{amznotes}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{etoolbox}

\graphicspath{ {./images/} }
\geometry{
    a4paper,
    headheight = 1.5cm
}

\patchcmd{\chapter}{\thispagestyle{plain}}
{\thispagestyle{fancy}}{}{}

\theoremstyle{remark}
\newtheorem*{claim}{Claim}
\newtheorem*{remark}{Remark}
\newtheorem{case}{Case}

\newcommand{\map}[3]{#1: #2 \rightarrow #3} % Mapping
\newcommand{\image}[2]{#2\left[#1\right]} % Image
\newcommand{\preimage}[2]{#2\left[#1\right]^{-1}} % Pre-image
\newcommand{\eval}[3]{\left. #1\right\rvert_{#2 = #3}} % Evaluated at

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

\begin{document}
\fancyhead[L]{
    Mathematical Analysis I
}
\fancyhead[R]{
    Lecture Notes
}
\tableofcontents

\chapter{The Real Numbers}
\section{Fields}
\begin{dfnbox}{Field}{field}
    A set $F$ with two binary operations, namely addition and multiplication, is called a {\color{red} \textbf{field}} if it satisfies the following axioms:
    \begin{enumerate}
        \item $\forall a, b \in F$, $a +_F b = b +_F a$.
        \item $\forall a, b, c \in F$, $(a +_F b) +_F c = a +_F (b +_F c)$.
        \item $\exists 0_F \in F$ such that $\forall a \in F$, $0_F +_F a = a +_F 0_F = a$.
        \item $\forall a \in F$, $\exists a' \in F$ such that $a +_F a' = 0_F$.
        \item $\forall a, b \in F$, $a \cdot_F b = b \cdot a$.
        \item $\forall a, b, c \in F$, $(a \cdot_F b) \cdot c = a \cdot_F (b \cdot_F c)$.
        \item $\forall a, b, c \in F$, $a \cdot_F (b +_F c) = a \cdot_F b +_F a \cdot_F b$ and $(a +_F b) \cdot_F c = a \cdot_F c +_F b \cdot_F c$.
        \item $\exists 1_F \in F$ such that $\forall a \in F$, $1_F \cdot_F a = a \cdot_F 1_F = a$.
        \item $\forall a \in F$, $\exists a' \in F$ such that $a \cdot_F a' = 1_F$.
    \end{enumerate}
\end{dfnbox}
If we denote addition by ``$+_F$'' and multiplication by ``$\cdot_F$'' or ``$\times_F$'', then we can denote the field over $F$ by $(F, +_F, \cdot_F)$ or $(F, +_F, \times_F)$.

Among the commonly used number sets, one may check that $\R$, $\Q$ and $\C$ are fields, while $\N$ and $\Z$ are not.
\subsection{Ordered Fields}
\begin{dfnbox}{Total Order}{totalOrder}
    A {\color{red} \textbf{total order}} on a set $X$ is a binary relation $\leq$ over $X$ such that for all $a, b, c \in X$:
    \begin{enumerate}
        \item $a \leq a$ (reflexive).
        \item $a \leq b$ and $b \leq c$ implies $a \leq c$ (transitive).
        \item $a \leq b$ and $b \leq a$ implies $a = b$ (antisymmetric).
        \item either $a \leq b$ or $b \leq a$ (strongly connected).
    \end{enumerate}
\end{dfnbox}
\begin{dfnbox}{Strict Total Order}{strictTotalOrder}
    A {\color{red} \textbf{strict total order}} on a set $X$ is a binary relation $<$ over $X$ such that for all $a, b, c \in X$:
    \begin{enumerate}
        \item $a \not < a$ (irreflexive).
        \item $a < b$ implies $b < a$ (asymmetric).
        \item $a < b$ and $b < c$ implies $a < c$ (transitive).
        \item if $a \neq b$, then either $a < b$ or $b < a$ (connected).
    \end{enumerate}
\end{dfnbox}
It is easy to see that the real numbers form the ordered fields $(\R, +, \times, \leq)$ and $(\R, +, \times, <)$. Note that this means $\R$ satisfies trichotomy. If we choose any $x \in \R$, then exactly one of~$x = 0$, $x > 0$ and $x < 0$ is true. Therefore, we can define that if $x \in \R$ and $x > 0$, then $x$ is said to be positive. This leads to the following axiomatic results:
\begin{enumerate}
    \item If $a$ and $b$ are both positive, then $a + b$ is positive;
    \item If $a$ and $b$ are both positive, then $ab$ is positive;
    \item For any $a \in \R$, either $a = 0$, $a$ is positive, or $-a$ is positive.
\end{enumerate}
Note that $a < b$ if and only if $b - a$ is positive. So the trichotomy of $\R$ guarantees that for any $a, b \in \R$, either $a = b$, $a < b$ or $b < a$ (i.e., $a > b$).

\section{Properties of $\R$}
We can derive a few obvious minor results based on the field properties of $\R$:
\begin{enumerate}
    \item If $a, b \in \R$, then $-ab + ab = 0$;
    \item For all $a \in \R$ with $a \neq 0$, $a^2 > 0$;
    \item If $a \in \R$ is such that $0 \leq a < \epsilon$ for all $\epsilon \in \R^+$, then $a = 0$;
    \item If $a < b$, then $a + c < b + c$ for all $c \in \R$.
    \item If $a < b$, then $ac < bc$ for all $c \in \R^+$ and $ac > bc$ for all $c \in \R^-$.
    \item For all $a \in \R$, $a^2 > 0$.
\end{enumerate}
We may consider the following interesting proposition:
\begin{probox}{}{infSmall}
    If $a \in \R$ is such that $0 \leq a < \epsilon$ for all $\epsilon \in \R^+$, then $a = 0$.
    \tcblower
    \begin{proof}
        Suppose on contrary that $a > 0$, then we can take $\epsilon_0 = \frac{a}{2}$. Note that $\epsilon_0 \in \R^+$ but $\epsilon_0 < a$, which is a contradiction. So $a = 0$.
    \end{proof}
\end{probox}
The above essentially asserts that \textbf{a non-negative real number is strictly less than any positive real number if and only if it is $0$}.

The properties of $\R$ also enables us to manipulate inequalities based on the following trivial results:
\begin{enumerate}
    \item If $ab > 0$, then $a$ and $b$ are either both positive or both negative;
    \item If $ab < 0$, then exactly one of them is positive and exactly one of them is negative.
\end{enumerate}
We shall introduce a few well-known inequalities.
\begin{thmbox}{Bernoulli's Inequality}{burnoulliIneq}
    If $x > -1$, then $(1 + x)^n \geq 1 + nx$ for all $n \in \N$.
    \tcblower
    \begin{proof}
        The case where $n = 0$ is trivial.
        \\\\
        Suppose that $(1 + x)^k \geq 1 + kx$ for some $k \in \N$, consider
        \begin{align*}
            (1 + x)^{k + 1} & = (1 + x)(1 + x)^k \\
            & \geq (1 + x)(1 + kx) \\
            & = 1 + (k + 1)x + kx^2 \\
            & \geq 1 + (k + 1)x.
        \end{align*}
        Therefore, $(1 + x)^n \geq 1 + nx$ for all $n \in \N$.
    \end{proof}
\end{thmbox}
\begin{thmbox}{AM-GM-HM Inequality}{AM-GM-HM}
    Let $n \in \N^+$ and let $a_1, a_2, \cdots, a_n$ be positive real numbers, then
    \begin{equation*}
        \frac{n}{\sum_{i = 1}^{n}\frac{1}{a_i}} \leq \left(\prod_{i = 1}^{n}a_i\right)^{\frac{1}{n}} \leq \frac{\sum_{i = 1}^{n}a_i}{n}.
    \end{equation*}
\end{thmbox}
\subsection{Absolute Value}
Given any real number $x$, intuitively we sense that $x$ possesses a certain ``distance'' from $0$. This distance can be formalised as follows:
\begin{dfnbox}{Absolute Value}{abs}
    Let $x \in \R$, the {\color{red} \textbf{absolute value}} of $x$ is defined as
    \begin{displaymath}
        \abs{x} = \begin{cases}
            x \quad & \textrm{if } x > 0 \\
            0 \quad & \textrm{if } x = 0 \\
            -x \quad & \textrm{if } x < 0
        \end{cases}.
    \end{displaymath}
\end{dfnbox}
We have some trivial properties about the absolute value:
\begin{enumerate}
    \item For all $a, b \in \R$, $\abs{ab} = \abs{a}\abs{b}$;
    \item For all $a \in \R$, $\abs{a}^2 = a^2$;
    \item If $c \geq 0$, then $\abs{a} \leq c$ if and only if $-c \leq a \leq c$ for all $a \in \R$;
    \item For all $a \in \R$, $-\abs{a} \leq a \leq \abs{a}$.
\end{enumerate}
Using these basic properties, we can prove the following results:
\begin{thmbox}{Triangle Inequality}{triIneq}
    For all $a, b \in \R$, $\abs{a + b} \leq \abs{a} + \abs{b}$.
\end{thmbox}
\begin{corbox}{Extended Triangle Inequality}{triIneqEx}
    For all $a, b \in \R$, $\abs{\abs{a} - \abs{b}} \leq \abs{a - b}$ and $\abs{a - b} \leq \abs{a} + \abs{b}$.
\end{corbox}
\begin{corbox}{Generalised Triangle Inequality}{triIneqGen}
    For all $a_1, a_2, \cdots, a_n \in \R$, 
    \begin{equation*}
        \abs{\sum_{i = 1}^{n}a_i} \leq \sum_{i = 1}^{n}\abs{a_i}.
    \end{equation*}
\end{corbox}
Analogously, if $\abs{x}$ represents the ``distance'' between $x$ and $0$, then by a simple translation we can see that $\abs{x - a}$ represents the ``distance'' between $x$ and $a$. Thus, we can have the following definition:
\begin{dfnbox}{Neighbourhood}{neighbourhood}
    Let $a \in \R$ and $\epsilon \in \R^+$. The {\color{red} \textbf{$\epsilon$-neighbourhood}} of $a$ is defined to be the set
    \begin{displaymath}
        V_\epsilon(a) \coloneqq \left\{x \in \R \colon \abs{x - a} < \epsilon\right\}.
    \end{displaymath}
\end{dfnbox}
Note that $x \in V_\epsilon(a)$ if and only if $-\epsilon < x - a < \epsilon$ or $a - \epsilon < x < a + \epsilon$. Which leads to the following interesting result:
\begin{probox}{}{xIsA}
    For any $a \in \R$, if $x \in V_\epsilon(a)$ for all $\epsilon \in \R^+$, then $x = a$.
    \tcblower
    \begin{proof}
        Note that this essentially means that $\abs{x - a} < \epsilon$ for all $\epsilon \in \R^+$. By Proposition \ref{pro:infSmall}, we have $\abs{x - a} = 0$ and therefore $x = a$.
    \end{proof}
\end{probox}

\subsection{The Completeness Property of $\R$}
Intuitively, there are no ``gaps'' among the real numbers, i.e., if you take any two real numbers, between them there is nothing else than other real numbers. Therefore, we say that $\R$ is \textit{complete}. This is in contrast with $\Q$ where there are gaps in between any two rational numbers (because there always exists some irrational numbers in between).

In this section, we probe into how the completeness of $\R$ can be established, and how the real numbers themselves can be constructed. To do that, we first establish the notion of \textit{boundedness}.

\begin{dfnbox}{Boundedness}{bound}
    Let $S \subseteq \R$. We say that $S$ is:
    \begin{itemize}
        \item {\color{red} \textbf{bounded above}} if there exists some $u \in R$ (known as the {\color{red} \textbf{upper bound}} of $S$) such that $u \geq s$ for all $s \in S$; 
        \item {\color{red} \textbf{bounded below}} if there exists some $v \in R$ (known as the {\color{red} \textbf{lower bound}} of $S$) such that $v \leq s$ for all $s \in S$; 
        \item {\color{red} \textbf{bounded}} if $S$ has both an upper bound and a lower bound;
        \item {\color{red} \textbf{unbounded}} either if $S$ has no upper bound or if $S$ has no lower bound;     
    \end{itemize}
\end{dfnbox}
\begin{notebox}
    \begin{remark}
        Note that $S$ is bounded if and only if there is some $M \geq 0$ such that $\abs{s} \leq M$ for all $s \in S$.
    \end{remark}
\end{notebox}

\chapter{Sequences and Series}
\section{Sequences}
Informally, a sequence is a list of enuerable numbers. This means that we can view a sequence as a mapping from an interval of $\N^+$ to $\R$. In this course, we will mainly focus on infinite sequences.
\begin{dfnbox}{Sequence}{seq}
    A {\color{red} \textbf{sequence}} in $\R$ is a real-valued function $X \colon \N^+ \to \R$. Where $X(n)$ is called the $n$-th {\color{red} \textbf{term}} of the sequence.
\end{dfnbox}
By convention, we denote $X(n)$ by $x_n$, and the sequence $X$ by $(x_n)$ or $(x_n \colon n \in \N^+)$.

Alternatively, a sequence $(x_n)$ may be defined in the following manner: first, we define the value of $x_1$. Secondly, we define a mapping $(x_1, x_2, \cdots, x_n) \mapsto x_{n + 1}$. Sequences defined in this way are said to be \textbf{inductively} and \textbf{recursively} defined.

\subsection{Limits of Sequences}
As $n$ becomes very large, a sequence may exhibit certain limiting behaviour.
\begin{dfnbox}{Convergence of Sequences}{seqConverge}
    A sequence $(x_n)$ defined in $\R$ is said to be {\color{red} \textbf{convergent}} to $x$ if for all $\epsilon > 0$, there exists some~$N \in \N$ such that whenever $n \geq N$, $\abs{x_n - x} < \epsilon$. $x$ is known as the {\color{red} \textbf{limit}} of $(x_n)$, denoted as
    \begin{equation*}
        \lim_{n \to \infty}x_n = x.
    \end{equation*}
\end{dfnbox}
A sequence which is not convergent is said to be \textit{divergent}.

Intuitively, a sequence can not converge to different values concurrently. This idea can be formulated formally as follows:
\begin{thmbox}{Uniqueness of Limits}{uniqueLimit}
    If $(x_n)$ converges, then its limit is unique.
    \tcblower
    \begin{proof}
        Suppose that $x$ and $x'$ are both limits of $(x_n)$. For all $\epsilon > 0$, there exists $N_1 \in \N^+$ such that
        \begin{equation*}
            \abs{x_n - x} < \frac{\epsilon}{2}
        \end{equation*}
        whenever $n \geq N_1$ and there exists $N_2 \in \N^+$ such that
        \begin{equation*}
            \abs{x_n - x'} < \frac{\epsilon}{2}
        \end{equation*}
        whenever $n \geq N_2$. Take $N = \max\{N_1, N_2\}$, then for all $n \geq N$,
        \begin{align*}
            \abs{x - x'} & = \abs{x - x_n + x_n - x'} \\
            & \leq \abs{x_n - x} + \abs{x_n - x'} \\
            & < \frac{\epsilon}{2} + \frac{\epsilon}{2} \\
            & = \epsilon
        \end{align*}
        for all $\epsilon > 0$. By Proposition \ref{pro:infSmall}, $x - x' = 0$, i.e., $x = x'$. This means that $\lim_{n \to \infty}x_n$ is unique.
    \end{proof}
\end{thmbox}
Given sequences $(x_n)$ and $(y_n)$, we can form new sequences by applying arithmetic operations onto them, and we can relate the limits of these new sequences with the limits of $(x_n)$ and $(y_n)$.
\begin{thmbox}{Limit Laws}{limitLaws}
    If $\lim_{n \to \infty}x_n = x$ and $\lim_{n \to \infty}y_n = y$, then
    \begin{enumerate}
        \item $\lim_{n \to \infty}(x_n + y_n) = x + y$.
        \item $\lim_{n \to \infty}(x_ny_n) = xy$.
        \item $\lim_{n \to \infty}(cx_n) = cx$ for all $c \in \R$.
        \item $\lim_{n \to \infty}\left(\frac{x_n}{y_n}\right) = \frac{x}{y}$.
    \end{enumerate}
\end{thmbox}
In some cases, it may not be easy to prove the existence of limit or compute it directly for a sequence. Thus, the following may be useful:
\begin{thmbox}{Squeeze Theorem}{squeeze}
    Let $(x_n)$, $(y_n)$ and $(z_n)$ be sequences such thatr $x_n \leq y_n \leq z_n$ for all $n \in \N^+$. If $(x_n)$ and $(z_n)$ both converge and $\lim_{n \to \infty}x_n = \lim_{n \to \infty}z_n = \ell$, then $(y_n)$ converges and
    \begin{equation*}
        \lim_{n \to \infty}y_n = \ell.
    \end{equation*}
    \tcblower  
    \begin{proof}
        Let $\epsilon > 0$ be an arbitrary real number. Note that there exists $N \in \N^+$ such that for all $n \geq N$,
        \begin{equation*}
            \abs{x_n - \ell} < \epsilon, \qquad \abs{z_n - \ell} < \epsilon.
        \end{equation*}
        Therefore,
        \begin{equation*}
            -\epsilon < x_n - \ell \leq y_n - \ell \leq z_n - \ell < \epsilon,
        \end{equation*}
        which implies that
        \begin{equation*}
            \abs{y_n - \ell} < \epsilon
        \end{equation*}
        for all $n \geq N$. Therefore, $\lim_{n \to \infty}y_n = \ell$.
    \end{proof}
\end{thmbox}
Notice that the limit of a sequence essentially ``bounds'' the sequence. This motivates us to investigate the relation between a convergent sequence and the its bounds.
\begin{dfnbox}{Boundedness of Sequences}{seqBound}
    A sequence $(x_n)$ in $\R$ is {\color{red} \textbf{bounded}} if there exists some $M \in \R^+$ such that $\abs{x_n} \leq M$ for all $n \in \N^+$.
\end{dfnbox}
\begin{notebox}
    \begin{remark}
        Note that $(x_n)$ is bounded if and only if the set $\left\{x_n \colon n \in \N^+\right\}$ is bounded.
    \end{remark}
\end{notebox}
\begin{thmbox}{Boundedness of Convergent Sequences}{convergeSeqBound}
    A sequence $(x_n)$ is bounded if it is convergent.
    \tcblower
    \begin{proof}
        Let $\lim_{n \to \infty}x_n = x$. Note that there exists some $N \in \N^+$ such that whenever~$n \geq N$, $\abs{x_n - x} < 1$. Consider
        \begin{align*}
            \abs{x_n} & = \abs{x_n - x + x} \\
            & \leq \abs{x_n - x} + \abs{x} \\
            & < 1 + \abs{x}.
        \end{align*}
        Let
        \begin{equation*}
            M \coloneqq \sup \big\{\abs{x_1}, \abs{x_2}, \cdots, \abs{x_{N - 1}}, 1 + \abs{x}\big\},
        \end{equation*}
        then $\abs{x_n} \leq M$ for all $n \in \N^+$, and so $(x_n)$ is bounded.
    \end{proof}
\end{thmbox}
The contrapositive statement to the above theorem concludes that \textbf{any unbounded sequence must be divergent}. However, note that the converse of Theorem \ref{thm:convergeSeqBound} is not true in general! As a counter example, consider $x_n = (-1)^n$.
\begin{probox}{}{positiveLimit}
    Let $(x_n)$ be a convergent sequence. If $x_n \geq 0$ for all $n \in \N^+$, then $\lim_{n \to \infty}x_n \geq 0$.
    \tcblower
    \begin{proof}
        Let $\lim_{n \to \infty}x_n = x$. Suppose on contrary $x < 0$, then $-x > 0$. Therefore, there exists some $N \in \N^+$ such that whenever $n \geq N$, $\abs{x_n - x} < -x$. This means that for all $n \geq N$,
        \begin{equation*}
            x_n < x - x = 0.
        \end{equation*}
        However, this is a contradiction, so $\lim_{n \to \infty}x_n = x > 0$.
    \end{proof}
\end{probox}
Here are two simple corollaries from Proposition \ref{pro:positiveLimit}, the proofs of which are left to the reader as an exercise.
\begin{corbox}{}{limitCorOne}
    If $(x_n)$ and $(y_n)$ are convergent sequences with $x_n \geq y_n$ for all $n \in \N^+$, then
    \begin{equation*}
        \lim_{n \to \infty}x_n \geq \lim_{n \to \infty}y_n.
    \end{equation*}
\end{corbox}
\begin{corbox}{}{limitCorTwo}
    If $(x_n)$ is a convergent sequence with $a \leq x_n \leq b$ for all $n \in \N^+$, then
    \begin{equation*}
        a \leq \lim_{n \to \infty}x_n \leq b.
    \end{equation*}
\end{corbox}
In casual languages, we may be tempted to describe the limit of a sequence as ``a value to which the terms can get as close as possible, but which is never surpassed''. This intuition gives us an idea to prove convergence for a bounded sequence.
\begin{dfnbox}{Monotone Sequences}{monotone}
    Let $(x_n)$ be a sequence. $(x_n)$ is said to be {\color{red} \textbf{increasing}} if $x_i \geq x_j$ whenever $i \geq j$, and {\color{red} \textbf{decreasing}} if $x_i \leq x_j$ whenever $i \geq j$. A sequence is said to be {\color{red} \textbf{monotone}} if it is either increasing or decreasing.
\end{dfnbox}
Note that an increasing sequence is the same as an non-decreasing sequence and vice versa. Recall that we have stated that the converse of Theorem \ref{thm:convergeSeqBound} is not true in general, but if we impose an additional constraint on the monotonicity of the bounded sequence, we will get a stronger condition.
\begin{thmbox}{Monotone Convergence Theorem}{monotoneConverge}
    Let $(x_n)$ be a monotone sequence in $\R$, then $(x_n)$ converges if and only if it is bounded.
    \tcblower
    \begin{proof}
        Suppose $(x_n)$ is convergent, then it follows from Theorem \ref{thm:convergeSeqBound} that it is bounded.
        \\\\
        Suppose conversely that $(x_n)$ is bounded. Without loss of generality, assume that $(x_n)$ is increasing, so $(x_n)$ has an upper bound. Let $\sup (x_n) = x$ and let $\epsilon > 0$ be an arbitrary real number. Note that $x - \epsilon$ is not an upper bound for $(x_n)$, so there exists some $x_N \in (x - \epsilon, x]$, which means that $0 \leq x - x_N < \epsilon$. Since $(x_n)$ is increasing, for all $n \geq N$, we have $x \geq x_n \geq x_N$, so
        \begin{equation*}
            0 \leq x - x_n \leq x - x_N < \epsilon.
        \end{equation*}
        Therefore, $\abs{x - x_n} < \epsilon$ for all $\epsilon > 0$ whenever $n \geq N$, and so $\lim_{n \to \infty}x_n = x$.
    \end{proof}
\end{thmbox}
A classic application of Theorem \ref{thm:monotoneConverge} is an approximation of $\sqrt{2}$.
\begin{exbox}{Mesopotamian Approximation of $\sqrt{2}$}{mesoApproxSqrt2}
    Define $(x_n)$ such that $x_1 = 2$ and $x_{n + 1} = \frac{1}{2}\left(x_n + \frac{2}{x_n}\right)$. Show that $\lim_{n \to \infty}x_n = \sqrt{2}$.
\end{exbox}
\subsection{Subsequences}
Recall that the sequence $x_n = (-1)^n$ is divergent. However, suppose we were to take all the odd terms from $(x_n)$ to form a new sequence, and to take all the even terms to form another new sequence. One would realise that both new sequences are convergent. This motivates us to study ``a part'' of a sequence as a new sequence.
\begin{dfnbox}{Subsequence}{subseq}
    Let $(x_n)$ be a sequence in $\R$ and let 
    \begin{displaymath}
        n_1 < n_2 < n_3 < \cdots < n_k < \cdots
    \end{displaymath}
    be an infinite sequence of strictly increasing positive integers, then the sequence $\left(x_{n_k}\right)$ is called a {\color{red} \textbf{subsequence}} of $(x_n)$.
\end{dfnbox}
\begin{notebox}
    \begin{remark}
        Note that a sequence is always a subsequence of itself.
    \end{remark}
\end{notebox}
Intuitively, if a sequence is convergent, then any of its subsequences should be convergent, too.
\begin{thmbox}{Convergence of Subsequences}{convergeSubseq}
    Let $(x_n)$ be a convergent sequence with $\lim_{n \to \infty}x_n = x$, then for any subsequence $(x_{n_k})$,
    \begin{equation*}
        \lim_{n_k \to \infty}x_{n_k} = \lim_{k \to \infty}x_{n_k} = x.
    \end{equation*}
    \tcblower
    \begin{proof}
        Note that for any $\epsilon > 0$, there exists some $N \in \N$ such that $\abs{x_n - x} < \epsilon$ for all $n \geq N$. Observe that $n_k \geq k$, so whenever $k \geq N$, we have $n_k \geq N$, and so
        \begin{equation*}
            \abs{x_{n_k} - x} < \epsilon
        \end{equation*}
        whenever $k \geq N$, i.e., 
        \begin{equation*}
            \lim_{n_k \to \infty}x_{n_k} = \lim_{k \to \infty}x_{n_k} = x.
        \end{equation*}
    \end{proof}
\end{thmbox}
Theorems \ref{thm:convergeSubseq} and \ref{thm:uniqueLimit} give rise to the following corollary. The proof is left to the reader as an exercise.
\begin{corbox}{}{subseqTwoLimits}
    Let $(x_n)$ be a sequence, then $(x_n)$ is divergent if there exists two subsequences $(x_{n_k})$ and $(x_{n_h})$ such that 
    \begin{equation*}
        \lim_{k \to \infty}x_{n_k} \neq \lim_{h \to \infty}x_{n_h}.
    \end{equation*}
\end{corbox}
We may apply Theorem \ref{thm:monotoneConverge} with respect to subsequences. Let us first introduce the notion of \textit{peak points}.
\begin{dfnbox}{Peak Point}{peakPt}
    Let $(x_n)$ be a sequence in $\R$, $x_m$ is called a {\color{red} \textbf{peak}} if for all $n \in \N$ with $n > m$, $x_m \geq x_n$.
\end{dfnbox}
Next, we shall prove that one can find a monotone subsequence from every sequence.
\begin{thmbox}{Existence of Monotone Subsequences}{existMonoSubseq}
    Every infinite sequence has an infinite monotone subsequence.
    \tcblower
    \begin{proof}
        Let $(x_n)$ be any sequence in $\R$. We consider the following cases:
        \\\\
        \textit{Case 1.} $(x_n)$ has infinitely many peak points.
        
        This means that there exists infinitely many $m_1, m_2, \cdots \in \N$ such that $m_j > m_i$ whenever $j > i$. Therefore, the subsequence $\left(x_{m_n}\right)$ is a monotone decreasing sequence.
        \\\\
        \textit{Case 2.} $(x_n)$ has finitely many peak points.
        
        This means that there exists $m_1, m_2, \cdots, m_k\in \N$ such that $x_{m_1}, x_{m_2}, \cdots, x_{m_k}$ are all the peak points of $(x_n)$. Take $N = m_k + 1$, then for all $n_{i} \geq N$, since $x_{n_i}$ is not a peak point, there exists some $n_{i + 1} > n_i$ such that $x_{n_{i + 1}} > x_{n_i}$. Therefore, $\left(x_{n_i}\right)$ is an increasing sequence.
    \end{proof}
\end{thmbox}
With these preparations done, we state the following theorem:
\begin{thmbox}{Bolzano-Weierstrass Theorem (simplified ver.)}{bolzanoWeierstrass}
    Every bounded sequence has a convergent subsequence.
    \tcblower
    \begin{proof}
        Let $(x_n)$ be a bounded sequence, then by Theorem \ref{thm:existMonoSubseq} we can find some subsequence $\left(x_{n_k}\right)$ which is monotone. Note that $\left(x_{n_k}\right)$ is also bounded, so by Theorem \ref{thm:monotoneConverge} it is convergent.
    \end{proof}
\end{thmbox}

\subsection{Cauchy Criterion}
Intuitively, if a sequence is convergent, then over a large interval of $\N$, the change in values of its terms will become smaller and smaller. Correspondingly, this means that the adjacent terms of the sequence will get closer and closer as $n$ becomes large.
\begin{dfnbox}{Cauchy Sequence}{cauchySeq}
    A sequence $(x_n)$ is said to be a {\color{red} \textbf{Cauchy sequence}} if for every $\epsilon > 0$, there exists some $H \in \N$ such that for all $n, m \in \N$ with $n, m \geq H$, $\abs{x_n - x_m} < \epsilon$.
\end{dfnbox}
We can make use of the Cauchy sequence to test for convergence.
\begin{thmbox}{Cauchy Convergence Criterion}{cauchyConvergeCri}
    A sequence in $\R$ is convergent if and only if it is a Cauchy sequence.
    \tcblower
    \begin{proof}
        Let $(x_n)$ be a sequence in $\R$. Suppose that $(x_n)$ converges to $x$, then for all~$\epsilon > 0$, there exists some $N \in \N$ such that whenever $n > N$, $\abs{x_n - x} < \frac{\epsilon}{2}$. Therefore, for all~$m, n > N$, we have
        \begin{align*}
            \abs{x_m - x_n} & = \abs{x_m - x - x_n + x} \\
            & \leq \abs{x_m - x} + \abs{x_n - x} \\
            & = \frac{\epsilon}{2} + \frac{\epsilon}{2} \\
            & = \epsilon,
        \end{align*}
        and so $(x_n)$ is a Cauchy sequence.
        \\\\
        Suppose conversely that $(x_n)$ is a Cauchy sequence on $\R$. We consider the following lemma:
        \begin{lembox}{Boundedness of Cauchy Sequences}{cauchySeqBound}
            A Cauchy sequence in $\R$ is bounded.
            \tcblower
            \begin{proof}
                Let $(x_n)$ be a Cauchy sequence, then by Definition \ref{dfn:cauchySeq}, there exists some~$H \in \N$ such that for all natural numbers $n \geq H$, $\abs{x_n - x_H} < 1$. By Corollary \ref{cor:triIneqEx}, we have
                \begin{equation*}
                    \big\lvert\abs{x_n} - \abs{x_H}\big\rvert \leq \abs{x_n - x_H} < 1,
                \end{equation*}
                and so $\abs{x_n} < \abs{x_H} + 1$. Take 
                \begin{equation*}
                    m = \max\big\{\abs{x_1}, \abs{x_2}, \cdots, \abs{x_H}, \abs{x_H} + 1\big\},
                \end{equation*}
                then $\abs{x_n} < m$ for all $n \in \N^+$.
            \end{proof}
        \end{lembox}
        Therefore, by Theorem \ref{thm:bolzanoWeierstrass} there exists a subsequence $\left(x_{m_n}\right)$ which converges to some $x \in \R$. Thus, there exists some $M \in \N$ such that $\abs{x_{m_n} - x} < \frac{\epsilon}{2}$ for all~$\epsilon > 0$ whenever $m_{n} > M$. By Definition \ref{dfn:cauchySeq}, there exists some $N \in \N$ such that~$\abs{x_n - x_{m_n}} < \frac{\epsilon}{2}$ for all $\epsilon > 0$ and for all $n, m_n > N$. Take $K = \max\{M, N\}$, then whenever $n > K$, there is some $m_n > K$ such that
        \begin{align*}
            \abs{x_n - x} & = \abs{x_n - x_{m_n} + x_{m_n} - x} \\
            & \leq \abs{x_n - x_{m_n}} + \abs{x_{m_n} - x} \\
            & = \frac{\epsilon}{2} + \frac{\epsilon}{2} \\
            & = \epsilon.
        \end{align*}
        Therefore, $\lim_{n \to \infty}x_n = x$.
    \end{proof}
\end{thmbox}

\chapter{Functions}
\section{Limits of Functions}
\begin{dfnbox}{Cluster Point}{clusterPt}
    Let $A \subseteq \R$. A point $c$ is called a {\color{red} \textbf{cluster point}} of $A$ if for all $\delta > 0$, there exists at least one $x \in A$ such that $0 < \abs{x - c} < \delta$, i.e., $\bigl(V_\delta(c) - \{c\}\bigr) \cap A \neq \varnothing$ for all $\delta > 0$.
\end{dfnbox}
Intuitively, this means that the elements of a set $A$ is \textbf{densely distributed} around the cluster point, which motivates the following alternative definition:
\begin{thmbox}{Alternative Definition of Cluster Points}{altClusterPt}
    Let $A \subseteq \R$, then $c \in \R$ is a cluster point of $A$ if and only if there exists a sequence $(a_n)$ in~$A$ such that $\lim_{n \to \infty}a_n = c$ and $a_n \neq c$ for all $n \in \N$.
    \tcblower
    \begin{proof}
        Suppose that $c$ is a cluster point of $A$. Fix any $n \in \N^+$, then there exists some $a_n \in A$ such that $0 < \abs{a_n - c} < \frac{1}{n}$. This means we can obtain a sequence $(a_n)$ with $a_n \neq c$ for all $n \in \N^+$.
        \\\\
        For any $\epsilon > 0$, note that there exists some $N \in \N^+$ such that $0 < \frac{1}{N} < \epsilon$. Therefore, for all $n \geq N$, we have $\abs{a_n - c} < \frac{1}{n} \leq \frac{1}{N} < \epsilon$, which means that $\lim_{n \to \infty}a_n = c$.
        \\\\
        Conversely, suppose that there is a sequence $(a_n)$ in $A$ with $a_n \neq c$ for all $n \in \N^+$ and $\lim_{n \to \infty}a_n = c$. For any $\delta > 0$, there is some $N \in \N^+$ such that for all $n \geq N$, $0 < \abs{a_n - c} < \delta$. Note that $a_n \in A$, so $c$ is a cluster point of $A$.
    \end{proof}
\end{thmbox}
Analogously to the limit of sequences, we may describe the limiting behaviour of a function as the follows:

As $x$ gets arbitrarily close to some point $c$, the function value $f(x)$ can get as close to a constant $L$ as possible.

The above intuition is formulated formally as follows:
\begin{dfnbox}{Limit of Functions}{funcLim}
    Let $f$ be a function over some $A \subseteq \R$. If $c$ is a cluster point of $A$, then $L \in \R$ is called the {\color{red} \textbf{limit}} of $f$ at $c$ if for all $\epsilon > 0$, there exists some $\delta \in \R$ such that whenever $0 < \abs{x - c} < \delta$, $\abs{f(x) - L} < \epsilon$. 
\end{dfnbox}

\chapter{Topology and Metric Spaces}
\section{Metric Space}
\begin{dfnbox}{Metric}{metric}
    A {\color{red} \textbf{metric}} on a set $S$ is a function $d \colon S \times S \to \R$ that satisfies the following:
    \begin{enumerate}
        \item $d(x, y) \geq 0$ for all $x, y \in S$ (positivity);
        \item $d(x, y) = 0$ if and only if $x = y$ (definiteness);
        \item $d(x, y) = d(y, x)$ for all $x, y \in S$ (symmetry);
        \item $d(x, y) \leq d(x, z) + d(z, y)$ for all $x, y, z \in S$ (triangular inequality).
    \end{enumerate}
\end{dfnbox}
\begin{notebox}
    \begin{remark}
        The metric is sometimes also called a {\color{red} \textbf{distance function}}.
    \end{remark}
\end{notebox}
\begin{dfnbox}{Metirc Space}{metricSpace}
    A {\color{red} \textbf{emtric space}} $(S, d)$ is a set $S$ together with a metric $d$ on $S$.    
\end{dfnbox}
In the Euclidean space $\R^n$, a usual definition for distance is
\begin{equation*}
    d_2(\mathbfit{x}, \mathbfit{y}) = \left[\sum_{i = 1}^{n}(y_i - x_i)^2\right]^{\frac{1}{2}}.
\end{equation*}
Note that $(\R^n, d_2)$ is a metric space, where $d_2$ is known as the \textit{Euclidean distance}. In general, we can prove that for any $p \in \N^+$,
\begin{equation*}
    d_p(\mathbfit{x}, \mathbfit{y}) = \left[\sum_{i = 1}^{n}\abs{y_i - x_i}^p\right]^{\frac{1}{p}}
\end{equation*}
is a metric over $\R^n$. Furthermore, notice that
\begin{equation*}
    \max_{i \in \N^+, i \leq n}\abs{y_i - x_i}^p \leq \sum_{i = 1}^{n}\abs{y_i - x_i}^p \leq n\max_{i \in \N^+, i \leq n}\abs{y_i - x_i}^p.
\end{equation*}
Taking the $p$-th root on all three parts, we have
\begin{equation*}
    \max_{i \in \N^+, i \leq n}\abs{y_i - x_i} \leq \left[\sum_{i = 1}^{n}\abs{y_i - x_i}^p\right]^{\frac{1}{p}} \leq n^{\frac{1}{p}}\max_{i \in \N^+, i \leq n}\abs{y_i - x_i}.
\end{equation*}
By Theorem \ref{thm:squeeze}, this allows us to define
\begin{equation*}
    d_\infty(\mathbfit{x}, \mathbfit{y}) = \lim_{p \to \infty}d_p(\mathbfit{x}, \mathbfit{y}) = \max_{i \in \N^+, i \leq n}\abs{y_i - x_i}.
\end{equation*}
$d_\infty(\mathbfit{x}, \mathbfit{y})$ can be alternatively written as $\norm{\mathbfit{x - y}}_\infty$, which is known as the \textit{infinite norm}.
\end{document}