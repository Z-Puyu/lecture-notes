\documentclass[math]{amznotes}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{etoolbox}
\usetikzlibrary{shapes.geometric}

\graphicspath{ {./images/} }
\geometry{
    a4paper,
    headheight = 1.5cm
}

\patchcmd{\chapter}{\thispagestyle{plain}}
{\thispagestyle{fancy}}{}{}

\theoremstyle{remark}
\newtheorem*{claim}{Claim}
\newtheorem*{remark}{Remark}
\newtheorem{case}{Case}

\newcommand{\map}[3]{#1: #2 \rightarrow #3} % Mapping
\newcommand{\image}[2]{#2\left[#1\right]} % Image
\newcommand{\preimage}[2]{#2\left[#1\right]^{-1}} % Pre-image
\newcommand{\eval}[3]{\left. #1\right\rvert_{#2 = #3}} % Evaluated at

\newenvironment{solution}
    {\let\oldqedsymbol=\qedsymbol
    \renewcommand{\qedsymbol}{\ }
    \begin{proof}[Solution]
    }
    {\end{proof}
    \renewcommand{\qedsymbol}{\oldqedsymbol}
    }

\begin{document}
\fancyhead[L]{
    Combinatorics and Graphs I 
}
\fancyhead[R]{
    Lecture Notes
}
\tableofcontents

\chapter{Permutations and Combinations}
\section{Basic Counting Principles}
An important motivation to study combinatorics is to count the \textbf{number of ways} in which an event may occur. Intuitively, we have two approaches to count.

The first approach is to categorise the event into \textbf{non-overlapping cases}. This means that we break an event into mutually exclusive sub-events, after which we can count the number of ways for each sub-event to occur. The agregate of these counts is the total number of ways for the original event to occur.

Those familiar with basic set theory may consider $E$ to be the set containing all distinct ways for an event to occur. By breaking up the event, we essentially establish a \textbf{partition} of~$E$, so that the sum of cardinalities of all the elements in that partition equals the cardinality of $E$.

This motivates us to write the following principle using set notations.
\begin{thmbox}{Addition Principle (AP)}{AP}
    Let $k \in \N^+$ and let $A_1, A_2, \cdots, A_k$ be $k$ finite sets which are pairwise disjoint, i.e. $A_i \cap A_j = \varnothing$ whenever~$i \neq j$, then
   \begin{equation*}
        \abs{\bigcup_{i = 1}^k A_i} = \sum_{i = 1}^{k}\abs{A_i}.
   \end{equation*} 
   \tcblower
   \begin{proof}
        The case where $k = 1$ is trivial.

        Suppose that when $k = n$, we have
        \begin{equation*}
            \abs{\bigcup_{i = 1}^n A_i} = \sum_{i = 1}^{n}\abs{A_i}
        \end{equation*} 
        for any $n$ finite sets which are pairwise disjoint. Let $A_{n + 1}$ be an arbitrary finite set which is disjoint with any of the $A_i$'s from the $n$ sets. So we have:
        \begin{align*}
            \abs{\bigcup_{i = 1}^{n + 1} A_i} & = \abs{\left(\bigcup_{i = 1}^n A_i\right) \cup A_{n + 1}} \\
            & = \abs{\bigcup_{i = 1}^n A_i} + \abs{A_{n + 1}} - \abs{\left(\bigcup_{i = 1}^n A_i\right) \cap A_{n + 1}} \\
            & = \left(\sum_{i = 1}^{n}\abs{A_i}\right) + \abs{A_{n + 1}} - \abs{\varnothing} \\
            & = \sum_{i = 1}^{n + 1}\abs{A_i}.
        \end{align*}
        Therefore, the original statement holds for all $k \in \N^+$.
   \end{proof}
\end{thmbox}
\begin{notebox}
    \begin{remark}
        In more casual language, this means that if an event $E_k$ has $n_k$ distinct ways to occur, then there is $\sum_{i = 1}^{k}n_k$ ways for at least one of the events $E_1, E_2, \cdots, E_k$ to occur, provided that $E_i$ and $E_j$ can never occur concurrently whenever $i \neq j$.
    \end{remark}
\end{notebox}
Given an event $E$, the other approach to count the number of ways for it to occur is to break~$E$ up internally into \textbf{non-overlapping stages}.

With set notations, we can write the $i$-th stage for $E$ to occur as $e_i$, and so a way for $E$ to occur can be represented by an ordered tuple $(e_1, e_2, \cdots, e_k)$, where $k$ is the total number of stages to undergo for $E$ to occur.

Let $E_i$ denote the set of all distinct ways to undergo the $i$-th stage of $E$, then it is easy to see that $E$ is just the \textbf{Cartesian product} of all the $E_i$'s. Hence, we derive the following principle:
\begin{thmbox}{Multiplication Principle (MP)}{MP}
    Let $k \in \N^+$ and let $A_1, A_2, \cdots, A_k$ be $k$ pairwise disjoint finite sets, then
    \begin{equation*}
        \abs{\prod_{i = 1}^{k}A_i} = \prod_{i = 1}^{k}\abs{A_i}.
    \end{equation*}
    \tcblower
    \begin{proof}
        The case where $k = 1$ is trivial.

        Suppose that when $k = n$, we have
        \begin{equation*}
            \abs{\prod_{i = 1}^{n}A_i} = \prod_{i = 1}^{n}\abs{A_i}
        \end{equation*} 
        for any $n$ finite sets which are pairwise disjoint. Let $A_{n + 1}$ be an arbitrary finite set which is disjoint with any of the $A_i$'s from the $n$ sets. Take $a_i, a_j \in A_{n + 1}$. Note that for all $\mathbfit{a} \in \prod_{i = 1}^{n}A_i$, $(\mathbfit{a}, a_i) \neq (\mathbfit{a}, a_j)$ whenever $a_i \neq a_j$. This means that
        \begin{align*}
            \abs{\prod_{i = 1}^{n + 1}A_i} & = \abs{\prod_{i = 1}^{n}A_i \times A_{n + 1}} \\
            & = \abs{\prod_{i = 1}^{n}A_i}\abs{A_{n + 1}} \\
            & = \left(\prod_{i = 1}^{n}\abs{A_i}\right)\abs{A_{n + 1}} \\
            & = \prod_{i = 1}^{n + 1}\abs{A_i}
        \end{align*}
        Therefore, the original statement holds for all $k \in \N^+$.
    \end{proof}
\end{thmbox}
\begin{notebox}
    \begin{remark}
        In more casual language, this means that if an event $E$ requires $k$ stages to be undergone before it occurs and the $i$-th stage has $n_i$ ways to complete, then there is $\prod_{i = 1}^{k}n_k$ ways for $E$ to occur, provided that no two different stages complete concurrently.
    \end{remark}
\end{notebox}
Often times, it is not straight-forward to count directly due to the presence of restrictions. We shall consider the following:

Let $E$ be the set of all possible ways for an event to occur. Let $p$ be some predicate representing some restriction and let $E(p)$ denote the set of all possible ways for the event to occur while $p$ holds. Note that:
\begin{displaymath}
    E(p) \cup E(\neg p) = E \quad \textrm{and} \quad E(p) \cap E(\neg p) = \varnothing,
\end{displaymath}
i.e. $\left\{E(p), E(\neg p)\right\}$ is a partition of $E$. Therefore, to count the number of ways for the event to occur while $p$ holds, it suffices to compute $E(\neg p)$, i.e. find the number of ways for the event to occur while $p$ does not hold.
\begin{thmbox}{Principle of Complementation}{PC}
    Let $U$ be a set and let $E \subseteq U$, then 
    \begin{equation*}
        \abs{E} = \abs{U} - \abs{U - E}.
    \end{equation*}
\end{thmbox}
\begin{notebox}
    \begin{remark}
        It may also help to think the Principle of Complementation as an inverse of the Addition Principle, where
        \begin{displaymath}
            E = \bigcup_{i = 1}^n E_i
        \end{displaymath}
        is the total number of ways for an event to occur and $E_p$ is the number of ways for the event to occur with restriction $p$.
    \end{remark}
\end{notebox}
In some cases, it is difficult to count the objects directly. However, note that the events for which we are counting are just sets, so we can treat ``number of occurrences'' of an event as the \textbf{cardinality} of a set. Therefore, we have the following principles:
\begin{thmbox}{Injection Principle}{injPrinciple}
    Let $A$, $B$ be finite sets. If there exists an injection
    \begin{displaymath}
        f \colon A \hookrightarrow B,
    \end{displaymath}
    then $\abs{A} \leq \abs{B}$.
\end{thmbox}
\begin{thmbox}{Bijection Principle}{bijPrinciple}
    Let $A$, $B$ be finite sets. If there exists a bijection
    \begin{displaymath}
        f \colon A \to B,
    \end{displaymath}
    then $\abs{A} = \abs{B}$.
\end{thmbox}
\section{Permutations}
\subsection{Linear Permutations}
A fundamental problem in combinatorics is described as follows: given a set $S$, how many ways are there to arrange $r$ elements in $S$, i.e. how many \textbf{distinct sequences} can be formed using the elements in $S$ without repetition? The process of selecting elements from $S$ and arranging them as a sequence is known as \textbf{permutation}.

Note that forming a sequence using $r$ elements from a set $S$ is an event consisting of $r$ stages, as we need to select an element for each of the $r$ terms of the sequence. Suppose $S$ has $n$ elements. For the first term of the sequence, we can choose any of the elements in $S$, so there is $n$ ways to do it. For the second term, since we cannot repeat the elements, we are left with $n - 1$ choices. 

Continue choosing elements in this way, we realise that if we choose the terms sequentially, when we reach the $k$-th term we will be left with $n - k + 1$ options as the previous~$(k - 1)$ terms have taken away $(k - 1)$ elements. By Theorem \ref{thm:MP}, we know that the number of sequences which can be formed is given by $\prod_{i = 1}^{r}(n - r + i)$.
\begin{dfnbox}{Permutations}{permutations}
    Let $A$ be a finite set such that $\abs{A} = n$, an $r$-permutation of $A$ is a way to arrange $r$ elements of $A$, denoted as $P^n_r$ and given by
    \begin{equation*}
        P^n_r = \prod_{i = 1}^{r}(n - r + i) = \frac{n!}{(n - r)!}.
    \end{equation*}
\end{dfnbox}
With some algebraic manipulations, it is easy to derive the following formula, which we, however, will prove in a combinatorial manner.
\begin{thmbox}{}{permutationId}
    Let $n, r \in \N$ with $r \leq n$, then $P^{n + 1}_r = P^n_r + rP^n_{r - 1}$.
    \tcblower
    \begin{proof}
        Let $S = \left\{x \in \N^+ \colon x \leq n + 1\right\}$ represent $(n + 1)$ distinct objects. Consider a permutation of $S$:
        \\\\
        If $n + 1$ is not inside the permutation, this is equivalent to an $r$-permutation of~$S - \{n + 1\}$, so there are $P^n_r$ such permutations.
        \\\\
    If $n + 1$ is inside the permutation, it means we need to first find an $(r - 1)$-permuation of $S - \{n + 1\}$, which has $P^n_{r - 1}$ ways to do. After that, we need to insert~$n + 1$ into each of these $(r - 1)$-permutations. Note that for each of such permutations, there are $r$ positions into which we can place $n + 1$. Therefore, the total number of $r$-permuations of $S$ derived in this manner is $rP^n_{r - 1}$.
        \\\\
        Therefore, there are $P^n_{r} + rP^n_{r - 1}$ $r$-permutations of $S$, i.e. $P^{n + 1}_r = P^n_r + rP^n_{r - 1}$. 
    \end{proof}
\end{thmbox}

\subsection{Circular Permutations}
Consider arranging $n$ distinct objects around a circle. If the slots around the circle are uniquely labelled, this is exactly the same as permutations along a straight line.

However, if the slots are identical, i.e. we are arranging $n$ distinct objects around a circle with identical slots, only the \textbf{relative positions} of the objects matter.

Let $\mathbfit{x}_i$ be an arbitrary straight-line permutations of the $n$ objects and let $\mathbfit{y}_i$ be the corresponding circular permutation of the $n$ objects.

Note that if we translate every element in $\mathbfit{x}_i$ by $k$ positions, this will result in a different straight-line permutation $\mathbfit{x}_j$ but does not change the corresponding circular permutation because the relative positions of the objects remain unchanged.

Notice that $k$ can take the values $0, 1, 2, \cdots, n - 1$, so for the same set of $n$ distinct objects, every circular permutation is mapped to $n$ straight-line permutations.
\begin{dfnbox}{Circular Permutations}{circPermutation}
    Let $A$ be a finite set such that $\abs{A} = n$, a circular $r$ permutation of $A$ is a way to arrange~$r$ elements of $A$ around a circular locus, denoted as $Q^n_r$ and given by
    \begin{equation*}
        Q^n_r = \frac{P^n_r}{r} = \frac{n!}{r(n - r)!}.
    \end{equation*}
\end{dfnbox}

\subsection{Permutations with Repetitions}
Consider the following scenario: suppose $T_1, T_2, \cdots T_n$ are distinct labels and $a_1, a_2, \cdots, a_r$ are $r$ distinct objects. If we wish to associate each object with one label, then each of the ways to do so is a permutation, the terms of which are taken from the $T_i$'s. Notice that under this setting, the $T_i$'s are allowed to be repeated in a permutation.

To reason such problems, we first introduce the notion of a \textit{multi-set}.
\begin{dfnbox}{Multi-set}{multiset}
    The {\color{red} \textbf{multi-set}} is defined to be
    \begin{equation*}
        M \coloneqq \left\{r_1 \cdot a_1, r_2 \cdot a_2, \cdots, r_n \cdot a_n\right\},
    \end{equation*}
    where $a_i$ has $r_i$ identical copies.
\end{dfnbox}
Observe that in a permutation of such a multi-set $M$, the object $a_i$ is repeated $r_i$ times. This brings us to the following formula:
\begin{probox}{Generalised Formula for Permutations}{genPnr}
    Let $k \in \N^+$ and let $A_1, A_2, \cdots, A_k$ be $k$ distinct objects, where $A_i$ occurs $n_i > 0$ times for~$i = 1, 2, \cdots, k$, then each permutation for these objects, corresponds to a unique permutation of the multi-set
    \begin{displaymath}
        M = \left\{n_1 \cdot A_1, n_2 \cdot A_2, \cdots, n_k \cdot A_k\right\},
    \end{displaymath}
    and the total number of permutations is given by
    \begin{equation*}
        \frac{\left(\sum_{i = 1}^{k}n_i\right)!}{\prod_{i = 1}^{k}\left(n_i!\right)}.
    \end{equation*}
\end{probox}
We may also consider the special case where we want to form an $r$-permutation with $k$ objects, where each object can repeat an arbitrary number of times. Notice that this is equivalent to finding the permutations of the multi-set
\begin{displaymath}
    M = \left\{\infty \cdot a_1, \infty \cdot a_2, \cdots, \infty \cdot a_k\right\}.
\end{displaymath}
In this case, we can simply iterate through each of the slots in the $r$-permutation and choose the object to be placed there. Trivially, there are always $k$ choices for each slot.
\begin{probox}{A Special Case}{pnrSpe}
    Consider the multi-set
    \begin{displaymath}
        M = \left\{\infty \cdot a_1, \infty \cdot a_2, \cdots, \infty \cdot a_n\right\}.
    \end{displaymath}
    The number of $r$-permutations formed using the elements from $M$ is given by $n^r$.
\end{probox}


\section{Combinations}
Beside permutations, there are also occasions where we only care about which elements from a particular set are selected instead of the order of selection.

Note that if we want to find a selection of $r$ elements from a set $A$ where the order of selected elements does not matter, it is equivalent to finding a subset of $A$ containing $r$ elements. This motivates us to give the following definition:
\begin{dfnbox}{Combinations}{combinations}
    Let $A$ be a finite set such that $\abs{A} = n$, an $r$-combination of $A$ is a set $B \subseteq A$ with~$\abs{B} = r$. The number of combinations of $A$ is given by
    \begin{equation*}
        C^n_r = \frac{P^n_r}{P^r_r} = \frac{n!}{r!(n - r)!} = \begin{pmatrix}
            n \\
            r
        \end{pmatrix}.
    \end{equation*}
\end{dfnbox}
\begin{notebox}
    \begin{remark}
        Two obvious results:
        \begin{enumerate}
            \item If $r > n$ or $r < 0$, $C^n_r = 0$;
            \item $C^n_r = C^n_{n - r}$ (By Theorem \ref{thm:PC}).
        \end{enumerate}
    \end{remark}
\end{notebox}
Similar to permutations, we have the following important identity:
\begin{thmbox}{Pascal's Triangle}{pascalTri}
    Let $n$ be an integer with $n \geq 2$ and let $r$ be an integer with $0 \leq r \leq n$, then
    \begin{equation*}
        C^{n + 1}_r = C^{n}_{r - 1} + C^{n}_r.
    \end{equation*}
    \tcblower
    \begin{proof}
        Let $S = \left\{x \in \N^+ \colon x \leq n + 1\right\}$ represent $(n + 1)$ distinct objects. Consider an $r$-combination $T$ of $S$:
        \\\\
        If $n + 1 \notin T$, this is equivalent to an $r$-combination of $S - \{n + 1\}$, so there are $C^n_r$ such permutations.
        \\\\
        If $n + 1 \in T$, it suffices to find an $(r - 1)$-combination of $S - \{n + 1\}$, which has $C^n_{r - 1}$ ways to do.
        \\\\
        Therefore, there are $C^n_{r} + C^n_{r - 1}$ $r$-combinations of $S$, i.e. $C^{n + 1}_r = C^n_r + C^n_{r - 1}$. 
    \end{proof}
\end{thmbox}
\subsection{Counting Subsets}
A useful application of combinations, derived directly from the definition, is to count the number of subsets for a given set which is finite. In other words, given a set $A$ with $\abs{A} = n \in \N$, we wish to find a general formula for $\abs{\mathcal{P}(A)}$.

Let $A_i$ be the set of all subsets of $A$ whose cardinality is $i$, then clearly
\begin{equation*}
    \abs{\mathcal{P}(A)} = \sum_{i = 0}^{n}\abs{A_i} = \sum_{i = 0}^{n}C^n_i.
\end{equation*}
We can expand the above expression algebraically and realise that it simpifies to $2^n$. However, in a combinatorial perspective, we are able to prove this result in a more succint manner:
\begin{thmbox}{General Formula for $\abs{\mathcal{P}(A)}$}{cardPowerset}
    Let $A$ be a finite set. If $\abs{A} = n$, then $\abs{\mathcal{P}(A)} = 2^n$.
    \tcblower
    \begin{proof}
        Let $S$ be an arbitrary subset of $A$. Consider an arbitrary element $a \in A$, then either $a \in S$ or $a \notin S$. 
        \\\\
        Let $a_i \in A$ for $i = 1, 2, \cdots, n$. For all $S \in \mathcal{P}(A)$, We replace $a_i$ by $1$ if $a_i \in S$, and by $0$ otherwise. Let $B$ be the set of all binary sequences of length $n$. It is clear that there exists a bijection between $\mathcal{P}(A)$ and $B$, and so $\abs{\mathcal{P}(A)} = \abs{B}$.
        \\\\
        For each binary sequence of length $n$, each of its digits is either $0$ or $1$. By Theorem \ref{thm:MP}, this means that there are in total $2^n$ such binary sequences. Therefore,
        \begin{equation*}
            \abs{\mathcal{P}(A)} = \abs{B} = 2^n.
        \end{equation*}
    \end{proof}
\end{thmbox}

\subsection{Combinations with Repetitions}
Given a set of $n$ distinct objects, we wish to find the number of combinations taken from the set where any element is allowed to be selected for multiple times. To reason about such problems, we introduce the following notion of a \textit{multi-subset}.
\begin{dfnbox}{Multi-subset}{multisubset}
    Let $M = \left\{\infty \cdot a_1, \infty \cdot a_2, \cdots, \infty \cdot a_n\right\}$ be a multi-set where $n \in \N$. An $r$-element {\color{red} \textbf{multi-subset}} of $M$ is the set
    \begin{displaymath}
        \left\{m_1 \cdot a_1, m_2 \cdot a_2, \cdots, m_n \cdot a_n\right\}
    \end{displaymath}
    where each of the $m_i$'s is a non-negative integer such that $\sum_{i = 1}^{n}m_i = r$. We denote the number of $r$-element multi-subsets of $M$ by $H^n_r$.
\end{dfnbox}
Intuitively, we can view each of the $a_i$'s as a ``box'' which holds $m_i$ balls. Therefore, if we can find the ways to distribute a total of $r$ balls into the $n$ ``boxes'', each of the distribution will then correspond to a multi-subset of $M$!
\begin{probox}{A Formula for $H^n_r$}{hnrFormula}
    Let $M = \left\{\infty \cdot a_1, \infty \cdot a_2, \cdots, \infty \cdot a_n\right\}$, then the number of $r$-element multi-subsets of $M$ is given by
    \begin{equation*}
        H^n_r = C^{r + n - 1}_r.
    \end{equation*}
    \tcblower
    \begin{proof}
        Consider a binary string formed using $r$ zeros. Note that we can insert a number of ones into the binary string to partition the zeros into different sections. Now, suppose we insert $(n - 1)$ ones into the binary string, it will result in a binary string containing $r$ zeros and $(n - 1)$ ones, such that the zeros are partitioned into $n$ sections.
        \\\\
        We can then number the sections using $1, 2, 3, \cdots, n$. For the $i$-th section, the number of zeros is recorded as $m_i$. Notice that in this case, each of the binary strings will correspond to a multi-subset in the form of 
        \begin{displaymath}
            \left\{m_1 \cdot a_1, m_2 \cdot a_2, \cdots, m_n \cdot a_n\right\}.
        \end{displaymath}
        One can check that this will establish a bijection between the set of all multi-subsets containing $n$ distinct types of objects and the set of all binary strings with $r$ zeros and $(n - 1)$ ones.
        \\\\
        Therefore, the above has proven that $H^n_r = C^{r + n - 1}_r$.
    \end{proof}
\end{probox}

\section{Fun Problems Collection}
\begin{genbox}{No Consecutive}
    Let $X = \left\{x \in \N^+ \colon x \leq n\right\}$. Find the number of $r$-combinations of $X$ such that~$\abs{x_i - x_j} \geq 2$ whenever $i \neq j$.
    \tcblower   
    \begin{solution}
        Note that for each of the $r$-combinations of $X$, we can re-write it into a strictly increasing sequence $\{x_i\}_{i = 1}^r$ with $x_i \in X$ and $x_{i + 1} - x_i \geq 2$. Let the set of all such sequences be $S_X$. Consider the function
        \begin{displaymath}
            f \colon S_X \to Y
        \end{displaymath}
        where $f\left(\{x_i\}_{i = 1}^r\right) = \{x_i - i + 1\}_{i = 1}^r$ and $Y$ is the set of all strictly increasing sequences whose terms are integers bounded between $1$ and $n - r + 1$ inclusive.
        \\\\
        Take two different sequences $s_1, s_2 \in S_X$. Let the $k$-th terms of $s_1$ and $s_2$ be $k_1$ and $k_2$ respectively such that $k_1 \neq k_2$. Let $t_1 = f(s_1)$ and $t_2 = f(s_2)$, whose $k$-th terms are $h_1$ and $h_2$ respectively. Note that $h_1 = k_1 - k + 1 \neq k_2 - k + 1 = h_2$, so~$t_1 \neq t_2$, which means $f$ is injective.
        \\\\
        Take an arbitrary $\{y_i\}_{i = 1}^r \in Y$ and consider the sequence $\{y_i + i - 1\}_{i = 1}^r$. Note that~$1 \leq y_i \leq n - r + 1$, so $1 \leq y_i + i - 1 \leq n$ for $i = 1, 2, \cdots, r$, which means~$\{y_i + i - 1\}_{i = 1}^r \in S_X$. This means that for all $y \in Y$, there exists some $s \in S_X$ such that $f(s) = y$, so $f$ is surjective.
        \\\\
        Therefore, $f$ is a bijection and so
        \begin{equation*}
            \abs{S_X} = \abs{Y} = C^{n - r + 1}_r.
        \end{equation*}
    \end{solution}
\end{genbox}
\begin{genbox}{Top Secret}
    Six scientists are working on a secret project. They wish to lock up the documents in a cabinet so that the cabinet can be opened when and only when three or more of the scientists are present. Suppose that each lock has one and only one key with the locks being pairwise distinct.
    \begin{enumerate}
        \item What is the smallest number of locks needed?
        \item What is the smallest number of keys that each scientist needs to carry?
    \end{enumerate}
    \tcblower   
    \begin{solution}
        Let $S = \left\{s_1, s_2, s_3, s_4, s_5, s_6\right\}$ be the set of scientists and $L$ be the set of locks. Define $T$ to be the set of all subsets of $S$ with $2$ elements, then for any $P \in T$, $P$ is a pair of distinct scientists.
        \\\\
        Let $L_P \subseteq L$ be the set of locks which cannot be opened by the pair of scientists in $P$. Note that for all $P \in T$, $L_P \neq \varnothing$. 
        \\\\
        Consider $P, Q \in T$ with $P \neq Q$, then $\abs{P \cup Q} \geq 3$. Thus, $L_P \cap L_Q = \varnothing$. Now, define the function
        \begin{displaymath}
            f \colon T \to L
        \end{displaymath}
        such that $f(P) = \ell_P$ where $\ell_P$ is an arbitrary element from $L_P$ (note that we can do this without using Choice as each of the $L_P$'s is finite).
        \\\\
        Suppose that there exist $P, Q \in T$ with $P \neq Q$ such that $f(P) = f(Q) = \ell_0$. Notice that this would mean that $\ell_0 \in L_P \cap L_Q$, which is a contradiction. Therefore,~$f$ must be injective. Hence, 
        \begin{equation*}
            \abs{L} \geq \abs{T} = C^6_2 = 15.
        \end{equation*}
        Now, choose an arbitrary element from $S$, say $s_k$, and consider the set $S' = S - \{s_k\}$. Let $T'$ be the set of all subsets of $S'$ with $2$ elements, then for any $P \in T'$, $L_{P \cup \{s_k\}} = \varnothing$, i.e., $s_k$ must have the keys to open all locks which the pair $P$ cannot open with their own keys. Let this set of keys be $K_P$. Note that $L_P \cap L_Q = \varnothing$ whenever $P \neq Q$, so~$K_P \cap K_Q = \varnothing$ whenever $P \neq Q$. Let the set of all keys held by $s_k$ be $H_k$, then
        \begin{equation*}
            \abs{H_k} \geq \abs{S'} = C^5_2 = 10.
        \end{equation*}
    \end{solution}
\end{genbox}

\section{Distribution Problems}
Another problem in which we are interested is to \textbf{distribute} the objects from a collection into a finite number of sub-collections. Specifically, we consider the number of ways to
\begin{enumerate}
    \item distribute $r$ distinct objects into $n$ identical collections;
    \item distribute $r$ distinct objects into $n$ distinct collections;
    \item distribute $r$ identical objects into $n$ identical collections;
    \item distribute $r$ identical objects into $n$ distinct collections.
\end{enumerate}
These $4$ basic models of distribution problems give rise to many variations. One important tool to solve these problems is the \textit{Stirling Numbers}.
\subsection{Stirling Numbers}
\begin{dfnbox}{Stirling Numbers of the First Kind}{stirling1}
    Let $r, n \in \N$ such that $0 \leq n \leq r$, then the {\color{red} \textbf{Stirling Number of the First Kind}}, $s(r, n)$, is the number of ways to arrange $r$ {\color{red} \textbf{distinct}} onjects around $n$ {\color{red} \textbf{identical}} circles such that no circle is empty.
\end{dfnbox}
\begin{notebox}
    \begin{remark}
        Some obvious results:
        \begin{enumerate}
            \item $s(r, 0) = 0$ if $r \geq 1$.
            \item $s(r, r) = 1$ if $r \geq 0$.
            \item $s(r, 1) = (r - 1)!$ if $r \geq 2$.
            \item $s(r, r - 1) = C^r_2$ if $r \geq 2$.
        \end{enumerate}
    \end{remark}
\end{notebox}
One thing to take note of is that there is no general algebraic formula for $s(r, n)$. Instead, all Stirling Numbers of the First Kind follow a recurrence relation in $2$ parameters.
\begin{thmbox}{A Recurrence Relation for $s(r, n)$}{recurrence1}
    For $r, n \in \N^+$ and $r \leq n$, we have
    \begin{equation*}
        s(r, n) = s(r - 1, n - 1) + (r - 1)s(r - 1, n).
    \end{equation*}
    \tcblower   
    \begin{proof}
        Consider the set
        \begin{displaymath}
            \left\{x_1, x_2, \cdots, x_r\right\}
        \end{displaymath}
        to be the $r$ distinct objects. We consider two cases.
        \\\\
        If $x_r$ is distributed to a circle such that it is the only objects around that circle, it suffices to find the number of ways to arrange the rest $(r - 1)$ distinct objects around the rest $(n - 1)$ identical circles, which there are $s(r - 1, n - 1)$ ways to do.
        \\\\
        If $x_r$ is adjacent to some other object, we can first arrange the rest $(r - 1)$ distinct objects around the $n$ identical circles, which there are $s(r - 1, n)$ ways to do. After that, we can choose any one of the $(r - 1)$ spaces between two adjacent objects to slot in $x_r$. Therefore, there are $(r - 1)s(r - 1, n)$ ways to distribute the objects.
        \\\\
        By Theorem \ref{thm:AP}, the total number of distributions is 
        \begin{equation*}
            s(r, n) = s(r - 1, n - 1) + (r - 1)s(r - 1, n).
        \end{equation*}
    \end{proof}
\end{thmbox}

\subsection{Distinct Objects into Distinct Collections}
The easiest case for this distribution problem is that each collection contains at most one object, i.e., each collection either contains an object, or contains no object at all.
\begin{probox}{}{}
    The number of ways to distribute $r$ distinct objects into $n$ distinct collections such that each collection contains at most $1$ object is given by $P^n_r$.
\end{probox}
We then consider the case where each collection can contain any number of objects.
\begin{probox}{}{}
    The number of ways to distribute $r$ distinct objects into $n$ distinct collections such that each collection can contain any number of objects is given by
    \begin{equation*}
        \frac{(n + r - 1)!}{(n - 1)!}.
    \end{equation*}
\end{probox}

\section{Binomial and Multinomial Coefficients}
\subsection{Binomial Coefficients}
In previous sections on combinations, we have already introduced the ways to choose $r$ items from a collection of $n$ distinct items, the number of which is given by
\begin{displaymath}
    C^n_r = \begin{pmatrix}
        n \\
        r
    \end{pmatrix}.
\end{displaymath} 
In this section, we will see that there is a clear relation between the number of $r$-combinations to the \textit{binomial expansion}.
\begin{thmbox}{Binomial Expansion}{binomial}
    Let $n \in \N$, then
    \begin{equation*}
        (x + y)^n = \sum_{i = 0}^{n}\left[\begin{pmatrix}
            n \\
            i
        \end{pmatrix}x^{n - i}y^i\right].
    \end{equation*}
    \tcblower   
    \begin{proof}
        Note that 
        \begin{equation*}
            (x + y)^n = \prod_{i = 1}^{n}(x + y).
        \end{equation*}
        Let the coefficient of $x^{n - r}y^r$ be $k$, where $r$ is an integer with $0 \leq r \leq n$. Notice that $k$ is exactly the number of ways to choose $(n - r)$ copies of $x$'s from the distinct $n$ terms of $(x + y)$, which is given by
        \begin{equation*}
            \begin{pmatrix}
                n \\
                n - r
            \end{pmatrix} = \begin{pmatrix}
                n \\
                r
            \end{pmatrix}.
        \end{equation*}
        Therefore, summing up the terms, we have
        \begin{equation*}
            (x + y)^n = \sum_{i = 0}^{n}\left[\begin{pmatrix}
                n \\
                i
            \end{pmatrix}x^{n - i}y^i\right].
        \end{equation*}
    \end{proof}
\end{thmbox}
There are many nice algebraic properties about the binomial coefficient $\left(\begin{smallmatrix}
    n \\
    r
\end{smallmatrix}\right)$. Beside Theorem \ref{thm:pascalTri}, the following can be proven with a few simple algebraic manipulations:
\begin{enumerate}
    \item $\begin{pmatrix}
        n \\
        r
    \end{pmatrix} = \frac{n}{r}\begin{pmatrix}
        n - 1 \\
        r - 1
    \end{pmatrix}$.
    \item $\begin{pmatrix}
        n \\
        r
    \end{pmatrix} = \frac{n - r + 1}{r}\begin{pmatrix}
        n \\
        r - 1
    \end{pmatrix}$.
    \item $\begin{pmatrix}
        n \\
        m
    \end{pmatrix}\begin{pmatrix}
        m \\
        r
    \end{pmatrix} = \begin{pmatrix}
        n \\
        r
    \end{pmatrix}\begin{pmatrix}
        n - r \\
        m - r
    \end{pmatrix}$.
\end{enumerate}
We will focus on two important identities about the binomial coefficients, one of which is as follows:
\begin{thmbox}{Vandermonde's Identity}{vadermonde}
    Let $m, n, r \in \N$, then
    \begin{equation*}
        \sum_{i = 0}^{r}\left[\begin{pmatrix}
            m \\
            i
        \end{pmatrix}\begin{pmatrix}
            n \\
            r - i
        \end{pmatrix}\right] = \begin{pmatrix}
            m + n \\
            r
        \end{pmatrix}.
    \end{equation*}
    \tcblower   
    \begin{proof}
        Consider the set
        \begin{displaymath}
            X = \left\{a_1, a_2, \cdots, a_m, b_1, b_2, \cdots, b_n\right\}.
        \end{displaymath}
        Clearly, $\abs{X} = m + n$. Let $A \subseteq X$ such that $\abs{A} = r$, we consider the number of such $A$'s.
        \\\\
        Let $i$ be an integer with $0 \leq i \leq r$. If $A$ contains exactly $i$ elements from the $a_j$'s, then it will contain exactly $(r - 1)$ elements from the $b_j$'s. Therefore, the number of $A$'s for each $i = 1, 2, \cdots, r$ is given by
        \begin{equation*}
            \begin{pmatrix}
                m \\
                i
            \end{pmatrix}\begin{pmatrix}
                n \\
                r - i
            \end{pmatrix}.
        \end{equation*}
        However, we know that the total number of such $A$'s is just $C^{m + n}_r$, so we have
        \begin{equation*}
            \sum_{i = 0}^{r}\left[\begin{pmatrix}
                m \\
                i
            \end{pmatrix}\begin{pmatrix}
                n \\
                r - i
            \end{pmatrix}\right] = \begin{pmatrix}
                m + n \\
                r
            \end{pmatrix}.
        \end{equation*}
    \end{proof}
\end{thmbox}
Recall that in Theorem \ref{thm:pascalTri}, we essentially established a recurrence relation for the binomial coefficients. Thus in theory, it is possible to generate any binomial coefficient recursively. The following theorem illustrates this.
\begin{thmbox}{Chu Shih-Chieh (CSC) Identity}{CSC}
    Let $r, n, k \in \N$ with $n \geq r$, then
    \begin{equation*}
        \sum_{i = 0}^{n - r}\begin{pmatrix}
            r + i \\
            r
        \end{pmatrix} = \begin{pmatrix}
            n + 1 \\
            r + 1
        \end{pmatrix}, \qquad \sum_{i = 0}^{k}\begin{pmatrix}
            r + i \\
            i
        \end{pmatrix} = \begin{pmatrix}
            r + k + 1 \\
            k
        \end{pmatrix}.
    \end{equation*}
    \tcblower
    \begin{proof}
        Consider the set
        \begin{displaymath}
            X = \left\{x \in \N^+ \colon x \leq n + 1\right\}.
        \end{displaymath}
        We will count the number of $(r + 1)$-element subsets of $X$ in the following way:
        \\\\
        Fix $k$ to be the smallest element in some $Y \subseteq X$, then it suffices to choose $r$ elements from $X - \left\{x \in \N^+ \colon x \leq k\right\}$. Note that the maximum for $k$ is $n - r + 1$, and so there are $n - r + 1$ disjoint cases. Therefore, it is easy to see that the total number of subsets is given by
        \begin{displaymath}
            \sum_{i = 0}^{n - r}\begin{pmatrix}
                r + i \\
                r
            \end{pmatrix}.
        \end{displaymath}
        However, we know that this is equivalent to choosing $(r + 1)$ elements directly from $X$, so
        \begin{equation*}
            \sum_{i = 0}^{n - r}\begin{pmatrix}
                r + i \\
                r
            \end{pmatrix} = \begin{pmatrix}
                n + 1 \\
                r + 1
            \end{pmatrix}.
        \end{equation*}
        Note that $C^{r + i}_r = C^{r + i}_i$ and $C^{n + 1}_{r + 1} = C^{n + 1}_{n - r}$. Therefore, by setting $k = n - r$, it is obvious by symmetry that
        \begin{equation*}
            \sum_{i = 0}^{k}\begin{pmatrix}
                r + i \\
                i
            \end{pmatrix} = \begin{pmatrix}
                r + k + 1 \\
                k
            \end{pmatrix}.
        \end{equation*}
    \end{proof}
\end{thmbox}
\subsection{Multinomial Coefficients}
\begin{dfnbox}{Multinomial Coefficient}{multinomialCoeff}
    Let $m, n \in \N$, with $m \geq 1$. The {\color{red} \textbf{multinomial coefficient}}
    \begin{displaymath}
        \begin{pmatrix}
            n \\
            n_1, n_2, \cdots, n_m
        \end{pmatrix} = \frac{n!}{\prod_{i = 1}^{m}n_i!}
    \end{displaymath}
    is the number of ways to distribute $n$ distinct objects into $m$ distinct collections such that there are exactly $n_i$ objects in the $i$-th collection.
\end{dfnbox}
\begin{thmbox}{Multinomial Expansion}{multinomialEx}
    For $m, n \in \N+$, we have
    \begin{equation*}
        \left(\sum_{i = 1}^{m}x_i\right)^n = \sum_{\substack{\sum_{j = 1}^{m}n_j = n}} \begin{pmatrix}
            n \\
            n_1, n_2, \cdots, n_m
        \end{pmatrix}\prod_{i = 1}^{m}x_i^{n_i}.
    \end{equation*}
\end{thmbox}

\chapter{Pigeonhole Principle}
\section{Pigeonhole Principle}
\begin{thmbox}{Pigeonhole Principle}{PP}
    Let $k, n \in \N^+$. If at least $kn + 1$ distinct objects are distributed into $n$ distinct sets, then there exists a set $K$ such that $\abs{K} \geq k + 1$.
    \tcblower   
    \begin{proof}
        Let $a_1, a_2, \cdots, a_{kn + 1}$ be the $kn + 1$ distinct objects to be distributed into the sets~$K_1, K_2, \cdots, K_n$. Suppose there is no $i \in \N^+$ such that $\abs{K_i} \geq k + 1$, i.e. $K_i \leq k$ for all~$i = 1, 2, \cdots, n$.
        \\\\
        This means that $\sum_{i = 1}^{n}\abs{K_i} \leq kn < kn + 1$, which is a contradiction.
    \end{proof}
\end{thmbox}
Note that Pigeonhole Principle only guarantees existence rather than uniqueness. We may also consider the following generalised version:
\begin{thmbox}{Generalised Pigeonhole Principle}{GPP}
    Let $n, k_1, k_2, \cdots, k_n \in \N^+$. If at least $\left[\sum_{i = 1}^{n}k_i + (n - 1)\right]$ distinct objects are distributed into $n$ distinct sets $S_1, S_2, \cdots, S_n$, then there exists at least one $S_i$ for $i = 1, 2, \cdots, n$ such that $\abs{S_i} \geq k_i$.
    \tcblower   
    \begin{proof}
        Suppose there is no $i \in \N^+$ such that $\abs{S_i} \geq k_i$, i.e., $\abs{S_i} \leq k_i - 1$ for all $i = 1, 2, \cdots, n$
        \\\\
        This means that $\sum_{i = 1}^{n}\abs{K_i} \leq \sum_{i = 1}^{n}(k_i - 1) = \sum_{i = 1}^{n}k_i - n$, which is a contradiction.
    \end{proof}
\end{thmbox}
Note that by setting $k_1 = k_2 = \cdots = k_n = 2$ we get from Theorem \ref{thm:GPP} to Theorem \ref{thm:PP}.

The Pigeonhole Principle is closely linked to the \textit{Ramsey Types of Problems}.
\section{Ramsey Types of Problems}
The Ramsey Types of Problems are motivated by the following question statement:
\begin{exbox}{}{sixPts}
    Let $A_1, A_2, A_3, A_4, A_5, A_6$ be six arbitrary points in a plane. We join these points pairwise with either a {\color{red} \textbf{red}} line segment or a {\color{blue} \textbf{blue}} line segment. Prove that after each point has been joined with any other point, there exists at least one {\color{blue} \textbf{blue}} triangle or at least one {\color{red} \textbf{red}} triangle whose vertices are three of the six points.
    \tcblower   
    \begin{proof}
        Consider the line segments joining $A_h$ with the other five points. Note that this is equivalent to colouring $5$ line segments using either red or blue. By Theorem \ref{thm:PP}, this means that at least $3$ of these line segments have the same colour.
        \\\\
        Without loss of generality, suppose the line segments $A_hA_i$, $A_hA_j$ and $A_hA_k$ are red. Consider the line segments $A_iA_j$, $A_jA_k$ and $A_iA_k$. If they are all blue, then we will have a blue triangle. Otherwise, if any one of them is red, then those two vertices together with $A_h$ will form a red triangle.
    \end{proof}
\end{exbox}
We can extend the above question a bit. Suppose we have $17$ arbitrary points $X_1, X_2, \cdots, X_{17}$ in a plane and we join these points in the same way as Example \ref{ex:sixPts} but with three distinct colours: {\color{red} \textbf{red}}, {\color{blue} \textbf{blue}} and {\color{orange} \textbf{orange}}. Can we still guarantee the existence of at least on triangle whose sides are all of the same colour?

It turns out that we can! Again we can consider all line segments joining $X_1$ with the other $16$ vertices. By Theorem \ref{thm:PP}, we must have at least $6$ of them having the same colour. Without loss of generality, assume that these $6$ line segments are all red.

Now, examine these $6$ vertices joined to $X_1$ with the same-coloured line segments. If any line segment between these $6$ vertices is red, then we have a red triangle. Otherwise, the line segments joining these $6$ vertices are coloured with only two colours, and by Example \ref{ex:sixPts} we are guaranteed to have a triangle with all three sides having the same colour as well.

Going back to Example \ref{ex:sixPts}, one might notice that $6$ is the smallest possible number of vertices for us to guarantee the existence of such a triangle. In the case of $5$ vertices, consider:
\begin{center}
    \begin{tikzpicture}[mystyle/.style={draw,shape=circle,fill=green}]
        \def\ngon{5}
        \node[
            regular polygon,
            regular polygon sides=\ngon,
            minimum size=3cm
        ] (p) {};
        \foreach\x in {1,...,\ngon}{
            \node[mystyle] (p\x) at (p.corner \x){};
        }
        \draw [red, very thick] (p1) -- (p2) -- (p3) -- (p4) -- (p5) -- (p1);
        \draw [blue, very thick] (p1) -- (p3);
        \draw [blue, very thick] (p1) -- (p4);
        \draw [blue, very thick] (p2) -- (p4);
        \draw [blue, very thick] (p2) -- (p5);
        \draw [blue, very thick] (p3) -- (p5);
    \end{tikzpicture}
\end{center}
This motivates the following definitions:
\begin{dfnbox}{Clique}{clique}
    A {\color{red} \textbf{clique}} is defined to be a finite set of vertices such that every pair of vertices are adjacent to each other (i.e., there exists a line segment joining any two vertices). A clique with $k$ vertices is called a $k$-clique.
\end{dfnbox}
\begin{dfnbox}{Ramsey Number}{ramseyNum}
    Given $p, q \in \N^+$. The {\color{red} \textbf{Ramsey Number}} $R(p, q)$ is the smallest natural number $n$ such that for any colouring of the edges of an $n$-clique by $2$ colours, there exists either a monochromatic $p$-clique or a monochromatic $q$-clique.
\end{dfnbox}
\begin{notebox}
    \begin{remark}
        Some obvious results:
        \begin{itemize}
            \item $R(p, q) = R(q, p)$.
            \item $R(1, q) = 1$.
            \item $R(2, q) = q$.
        \end{itemize}
    \end{remark}
\end{notebox}
These develop into what we now know as \textit{Ramsey Theory} which probes into the question:
\begin{quote}
    How many elements of a particular structure $S$ must there exist to guarantee that a certain property $p$ will always hold for $S$?
\end{quote}
It turns out that calculating the Ramsey Numbers can be extremely difficult. However, we do have a way to establish an upper bound for each of the Ramsey Numbers.
\begin{thmbox}{Recurrence Relation of Ramsey Numbers}{recurRamsey}
    For all integers $p, q \geq 2$,
    \begin{equation*}
        R(p, q) \leq R(p - 1, q) + R(p, q - 1).
    \end{equation*}
    In particular, if both $R(p - 1, q)$ and $R(p, q - 1)$ are even, then
    \begin{equation*}
        R(p, q) \leq R(p - 1, q) + R(p, q - 1) - 1.
    \end{equation*}
    \tcblower
    \begin{proof}
        Let $n = R(p - 1, q) + R(p, q - 1)$. To prove that $R(p, q) \leq n$, it suffices to prove that for any $n$-clique, any colouring of its edges using blue and red will result in either a blue $p$-clique or a red $q$ clique.
        \\\\
        Consider an arbitrary vertex $V$ of any $n$-clique. Note that $V$ is incident with $\left(R(p - 1, q) + R(p, q - 1) - 1\right)$ vertices and edges. By Theorem \ref{thm:GPP} this means that either at least $R(p - 1, q)$ edges are blue or at least $R(p, q - 1)$ edges are red.
        \\\\ 
        Without loss of generality, consider the $R(p - 1, q)$-clique whose vertices are joined to $V$ by blue edges. By Definition \ref{dfn:ramseyNum}, this clique contains either a blue $(p - 1)$-clique or a red $p$-clique. If it contains a red $p$-clique, then we are done. If it contains a blue $(p - 1)$-clique, this clique together with $V$ will form a blue $p$-clique. Either way, it is guaranteed that
        \begin{equation*}
            R(p, q) \leq n = R(p - 1, q) + R(p, q - 1).
        \end{equation*}
        Now we proceed to proving the case where $R(p - 1, q)$ and $R(p, q - 1)$ are both even.
        \\\\
        Let $m = R(p - 1, q) + R(p, q - 1) - 1$. Fix an arbitrary vertex $W$, then it suffices to prove that among the $(m - 1)$ edges incident to $W$, either at least $R(p - 1, q)$ are blue or at least $R(p, q - 1)$ are red.
        \\\\
        Suppose on contrary that there are exactly $\left(R(p - 1, q) - 1\right)$ blues edges and exactly $\left(R(p, q - 1) - 1\right)$ red edges for all vertices in the $m$-clique. This means that the total number of blue edges in the $m$-clique is
        \begin{equation*}
            N = \frac{m\left(R(p - 1, q) - 1\right)}{2}.
        \end{equation*}
        However, $m$ and $R(p - 1, q) - 1$ are both odd, this means that $N$ is not an integer, which is impossible.
    \end{proof}
\end{thmbox}
The above recurrence allows us to prove the following theorem:
\begin{thmbox}{Ramsey's Theorem}{RamseyThm}
    For all $p, q \in N^+$, the Ramsey Number $R(p, q)$ always exists.
\end{thmbox}

\chapter{Principle of Inclusion and Exclusion}
\section{Principle of Inclusion and Exclusion (PIE)}
\begin{thmbox}{Principle of Inclusion and Exclusion (a special case)}{2PIE}
    Let $A$ and $B$ be two finite sets, then
    \begin{equation*}
        \abs{A \cup B} = \abs{A} + \abs{B} - \abs{A \cap B}.
    \end{equation*}
    In particular, if $A$ and $B$ are disjoint, then $\abs{A \cup B} = \abs{A} + \abs{B}$.
\end{thmbox}
\begin{thmbox}{Principle of Inclusion and Exclusion (general)}{PIE}
    Let $E_1, E_2, \cdots, E_n$ be a sequence of finite sets. In general, we have
    \begin{equation*}
        \abs{\bigcup_{i = 1}^n E_i} = \sum_{j = 1}^{n} \left[(-1)^{j + 1}\left(\sum_{1 \leq k_1 \leq k_2 \leq \cdots \leq k_j \leq n}\abs{\bigcap_{h = 1}^{j}E_{k_h}}\right)\right].
    \end{equation*}
    \tcblower
    \begin{proof}
        Define a function $f_S \colon S \to \{0, 1\}$ by
        \begin{equation*}
            f_S(x) = \begin{cases}
                1 \quad \textrm{if } x \in S \\
                0 \quad \textrm{if } x \notin S
            \end{cases}.
        \end{equation*}
        Let $E = \bigcup_{i = 1}^n E_i$. Consider
        \begin{equation}\label{eq:1}
            \prod_{i = 1}^{n}\left(f_E(x) - f_{E_i}(x)\right). \tag{*}
        \end{equation}
        For any $x$, if $x \in E$, then $x \in E_k$ for some $k \in \left\{x \in \N \colon x \leq n\right\}$, which means that $f_E(x) - f_{E_k}(x) = 0$; if $x \notin E$, then $f_E(x) = f_{E_i}(x) = 0$ for all $i \in \left\{x \in \N \colon x \leq n\right\}$. In either case, (\ref{eq:1}) is identically $0$.
        \\\\
        Note that for any sets $A$, $B$, $f_{A \cap B}(x) = f_A(x)f_B(x)$.
    \end{proof}
\end{thmbox}

\section{General Principle of Inclusion and Exclusion (GPIE)}
\begin{thmbox}{General Principle of Inclusion and Exclusion}{GenPIE}
    Let $S$ be an $n$-element set and let $\left\{P_1, P_2, \cdots P_q\right\}$ be a set of properties. Suppose that $E(m)$ is the number of elements in $S$ that satisfy exactly $m$ of the $q$ properties and that $\omega(P_{i_1}P_{i_2}\cdots P_{i_m})$ is the number of elements in $S$ that satisfy exactly $P_{i_1}, P_{i_2},\cdots, P_{i_m}$, such that
    \begin{equation*}
        \omega(m) = \sum \omega(P_{i_1}P_{i_2}\cdots P_{i_m}),
    \end{equation*}
    then
    \begin{equation*}
        E(m) = \sum_{k = m}^{q}(-1)^{k - m}\begin{pmatrix}
            k \\
            m
        \end{pmatrix}\omega(k).
    \end{equation*}
\end{thmbox}

\section{Stirling Numbers of the Second Kind}
\begin{dfnbox}{Stirling Number of the Second Kind}{2ndStirling}
    The {\color{red} \textbf{Stirling Number of the Second Kind}}, denoted as $S(r, n)$, is the number of ways to distribute $r$ distinct objects into $n$ indentical collections such that no collection is empty.
\end{dfnbox}
\begin{notebox}
    \begin{remark}
        Some trivial results:
        \begin{itemize}
            \item $S(0, 0)$ = 1.
            \item $S(r, 0) = S(0, n) = 0$ for all $r, n \in \N^+$.
            \item $S(r, n) > 0$ for all $r, n \in \N$ with $r \geq n \geq 1$.
            \item $S(r, n) = 0$ if $n > r \geq 1$.
            \item $S(r, 1) = S(r, r) = 1$ for all $r \in \N^+$.
        \end{itemize}
    \end{remark}
\end{notebox}
\begin{thmbox}{Recurrence Relation of $S(r, n)$}{SrnRecur}
    For all $r, n \in \N$ with $r \geq n$,
    \begin{equation*}
        S(r, n) = S(r - 1, n - 1) + n(r - 1, n).
    \end{equation*}
\end{thmbox}
\begin{dfnbox}{Partition}{partition}
    Let $A$ be a set, an $n$-partition of $A$ is a set $S \subset \mathcal{P}(A)$ such that for all $S_1, S_2 \in S$ with $S_1 \neq S_2$, $S_1 \cap S_2 = \varnothing$ and $\bigcup S = A$.
\end{dfnbox}
Note that the number of all partitions of $A$ with $\abs{A} = n$ is just
\begin{equation*}
    \sum_{i = 1}^{n}S(n, i).
\end{equation*}
\begin{thmbox}{Number of Surjective Mappings}{numSurj}
    Let $F(r, n)$ where $r, n \in \N^+$ deonote the number of surjective mappings
    \begin{equation*}
        f \colon [r] - \{0\} \to [n] - \{0\},
    \end{equation*}
    then
    \begin{equation*}
        F(r, n) = \sum_{k = 0}^{n}(-1)^k \begin{pmatrix}
            n \\
            k
        \end{pmatrix}(n - k)^r.
    \end{equation*}
\end{thmbox}
Some corollaries:
\begin{align*}
    \frac{1}{n!} \sum_{k = 0}^{n}(-1)^k \begin{pmatrix}
        n \\
        k
    \end{pmatrix}(n - k)^r & = S(r, n) \\
    \sum_{k = 0}^{n}(-1)^k \begin{pmatrix}
        n \\
        k
    \end{pmatrix}(n - k)^r & = 0 \quad \textrm{if }n > r \geq 1
\end{align*}
\section{Derangement}
\begin{dfnbox}{Derangement}{derangement}
    Let $N_n = [n] - \{0\}$. A {\color{red} \textbf{derangement}} of $N_n$, denoted by $D_n$, is the permutation $a_1a_2\cdots a_n$ of $N_n$ such that $a_i \neq i$ for all $i = 1, 2, \cdots, n$.
    \\\\
    In general, we also say that an $r$-permutation of $N_n$ has a {\color{red} \textbf{fixed point}} at $i$ if $a_i = i$. The number of $r$-permutations of $N_n$ with $k$ fixed points is $D(n, r, k)$.
\end{dfnbox}
\begin{thmbox}{A Formula for $D(n, r, k)$}{dnrk}
    For $n \geq r \geq k \geq -$ and $r \geq 1$,
    \begin{equation*}
        D(n, r, k) = \frac{C^r_k}{(n - r)!}\sum_{i = 0}^{r - k}(-1)^i \begin{pmatrix}
            r - k \\
            i
        \end{pmatrix}(n - k - i)!.
    \end{equation*}
\end{thmbox}
Note that the number of derangement
\begin{equation*}
    D_n = D(n, n, 0) = n!\sum_{i = 0}^{n}\frac{(-1)^i}{i!}.
\end{equation*}
And so
\begin{equation*}
    \lim_{n \to \infty}P(\textrm{Having a derangement}) = \lim_{n \to \infty}\frac{D_n}{n!} = \mathrm{e}^{-1}.
\end{equation*}

%\section{Euler $\phi$-Function}
%\begin{thmbox}{Euler $\phi$-Function}
    
%\end{thmbox}

\chapter{Generating Functions}
\section{Ordinary Generating Functions}
\begin{dfnbox}{Ordinary Generating Function (OGF)}{OGF}
    Let $(a_r)$ be a sequence in $\R$. The {\color{red} \textbf{ordinary generating function}} of $(a_r)$ is defined to be the series
    \begin{equation*}
        A(x) = \sum_{i = 0}^{\infty}a_ix^0.
    \end{equation*}
\end{dfnbox}
Note that the set of generating functions is a vector space.
\begin{dfnbox}{Generalised Binomial Coefficients}{}
    Let $\alpha \in \R$ and $r \in \N$, then 
    \begin{equation*}
        \begin{pmatrix}
            \alpha \\
            r
        \end{pmatrix} = \frac{\prod_{i = 0}^{r - 1}(\alpha - i)}{r!}.
    \end{equation*}
\end{dfnbox}

\begin{dfnbox}{Generalised Binomial Expansion}{}
    Let $\alpha \in \R$ then 
    \begin{equation*}
        (1 \pm x)^\alpha = \sum_{r = 0}^{\infty}\begin{pmatrix}
            \alpha \\
            r
        \end{pmatrix}(\pm x)^r.
    \end{equation*}
\end{dfnbox}
Notice that
\begin{equation*}
    (1 - x)^{-n} = \sum_{i = 0}^{\infty} = \begin{pmatrix}
        n - 1 + i \\
        i
    \end{pmatrix}x^i.
\end{equation*}
More generally, the GF for $\left(1, k, k^2, \cdots\right)$ is $\frac{1}{1 - kx}$.

\section{Modelling with Generating Functions}

\chapter{Recurrence Relations}

\chapter{Introduction to Graphs}
\section{Terminologies}
\begin{dfnbox}{Multigraph}{multigraph}
    A {\color{red} \textbf{multigraph}} $G$ consists of a non-empty finite set of vertices denoted by $V(G)$ and a finite set of edges denoted by $E(G)$.
    \\\\
    The {\color{red} \textbf{order}} of $G$ is denoted by $v(G) = \abs{V(G)}$ and the {\color{red} \textbf{size}} of $G$ is denoted by $e(G) = \abs{E(G)}$.
    \\\\
    In particular, if $v(G) = m$ and $e(G) = n$, we say that $G$ is an {\color{red} \textbf{$(m, n)$-graph}}.
    \\\\
    $G$ is said to be {\color{red} \textbf{trivial}} if $v(G) = 1$ and {\color{red} \textbf{non-trivial}} otherwise.
\end{dfnbox}

\begin{dfnbox}{Simple Graph}{simpleGraph}
    A multigraph $G$ is said to be {\color{red} \textbf{simple}} if there is at most one edge between any two distinct vertices.
\end{dfnbox}
\begin{notebox}
    \begin{remark}
        Note that if $G$ is simple, then
        \begin{displaymath}
            E(G) \subseteq \left\{(v_j, v_i) \colon v_j, v_i \in V(G), j > i\right\}.
        \end{displaymath}
    \end{remark}
\end{notebox}
\begin{dfnbox}{Adjacency}{adjacent}
    Let $v_i, v_j \in V(G)$, we say that they are {\color{red} \textbf{adjacent}} if $v_iv_j \in E(G)$. Alternatively, we say that $v_i$ and $v_j$ are {\color{red} \textbf{neighbours}} to each other. The edge $v_iv_j$ is said to be {\color{red} \textbf{incident}} with $v_i$ and $v_j$. Two edges $e$ and $f$ are said to be {\color{red} \textbf{adjacent}} if there exists some $v \in V(G)$ such that both $e$ and $f$ are incident with $v$. 
    \\\\
    The number of edges incident to $v$ is called the {\color{red} \textbf{degree}} of $v$, denoted by $d_G(v)$. If $d_G(v)$ is even (repectively, odd), then we say that $v$ is an even (respectively, odd) vertex. If $d_G(v) = 0$, we say that $v$ is {\color{red} \textbf{isolated}}; if $d_G(v) = 1$, we say that $v$ is an {\color{red} \textbf{end}} vertex. If $d_G(v) = k$ for all $v \in V(G)$, $G$ is known as a {\color{red} \textbf{$k$-regular graph}}.
    \\\\
    The set of all neighbours to some $v_i \in V(G)$ is called the {\color{red} \textbf{neighbourhood set}} of $v_i$, denoted by $N_G(v_i)$. In particular, the set $N_G[v_i] \coloneqq N_G(v_i)\cup\{v_i\}$ is known as the {\color{red} \textbf{closed neighbourhood set}} of $v_i$.
\end{dfnbox}
\begin{dfnbox}{Empty and Complete Graphs}{empCom}
    Let $G$ be a simple graph. $G$ is said to be an {\color{red} \textbf{empty graph}} if $e(G) = 0$, and a {\color{red} \textbf{complete graph}} if for all $u, v \in V(G)$, $(u, v) \in E(G)$. 
\end{dfnbox}
\begin{dfnbox}{Subgraph}{subgraph}
    Let $G, H$ be graphs, then $H$ is a {\color{red} \textbf{subgraph}} of $G$ if $V(H) \subseteq V(G)$ and $E(H) \subseteq E(G)$. In particular, $H$ is a {\color{red} \textbf{proper subgraph}} of $G$ if $V(H) \subset V(G)$ and $E(H) \subset E(G)$.
\end{dfnbox}
\begin{dfnbox}{Spanning Subgraph}{spanSubgraph}
    Let $H$ be a subgraph of $G$. $H$ is called a {\color{red} \textbf{spanning subgraph}} of $G$ if $V(H) = V(G)$.
\end{dfnbox}
\begin{dfnbox}{Induced Subgraph}{induceSubgraph}
    Let $H$ be a subgraph of $G$. $H$ is called a {\color{red} \textbf{induced subgraph}} of $G$ if
    \begin{equation*}
        E(H) = \left\{uv \in E(G) \colon u, v \in V(H)\right\}.
    \end{equation*}
    Let $S \subseteq V(G)$, the subgraph of $G$ induced by $S$ is denoted by $[S]$.
    \\\\
    Alternatively, let $F \subseteq E(G)$. Define
    \begin{equation*}
        V' \coloneqq \bigcup \left\{\left\{u, v\right\} \colon uv \in F\right\},
    \end{equation*}
    then $(V', F)$ is the subgraph of $G$ induced by $F$, denoted by $G[F]$.
\end{dfnbox}
\section{Graph Traversal}
\begin{dfnbox}{Walk, Trail, Path}{wtp}
    Let $G$ be a graph and $x, y \in V(G)$, then an {\color{red} \textbf{$x$-$y$ walk}} is an alternating sequence
    \begin{equation*}
        W \coloneqq v_0e_1v_1e_2v_2\cdots v_{n - 1}e_nv_n
    \end{equation*}
    where $v_i \in V(G)$, $e_i = v_{i - 1}v_i \in E(G)$, $x = v_0$ and $y = v_n$. In particular, $W$ is {\color{red} \textbf{open}} if $v_0 \neq v_n$ and {\color{red} \textbf{closed}} otherwise. The {\color{red} \textbf{length}} of a walk is defined as the number of edges in it.
    \\\\
    If $e_i \neq e_j$ whenever $i \neq j$, then $W$ is called a {\color{red} \textbf{trail}}. A closed trail is called a {\color{red} \textbf{circuit}}. If $v_i \neq v_j$ whenever $i \neq j$, then $W$ is called a {\color{red} \textbf{path}}. A closed path is called a {\color{red} \textbf{cycle}}.
\end{dfnbox}
\begin{notebox}
    \begin{remark}
        All paths are trails and all trails are walks, but the converses are not true.
    \end{remark}
\end{notebox}
Note that a path is essentially a gragh. We denote a path of order $n$ by $P_n$ and a cycle of order $n$ by $C_n$.

A common tool in proofs of graph theory is the \textbf{extremal approach}, which can be demonstrated in the proposition below.
\begin{probox}{}{}
    If a graph $G$ conatins a $u$-$v$ walk of length $k$, then $G$ contains a $u$-$v$ path of length at most $k$.
\end{probox}
\begin{dfnbox}{Connected Graph}{connected}
    A vertex set $U \subseteq V(G)$ is said to be {\color{red} \textbf{connected}} if for any $u, v \in U$, there exists a path from $u$ to $v$
\end{dfnbox}
Note that connectedness is an equivalence relation. Let $P$ be a partition formed by the equivalence classes of $G$ under the connectedness relation, then any $c(G) \in P$ induces a subgraph $[c(G)]$.
\begin{dfnbox}{Complement}{comp}
    Let $G$ be a graph of order $n$, the {\color{red} \textbf{complement}} of $G$, denoted by $\bar{G}$ is the graph of order $n$ where
    \begin{equation*}
        V(\bar{G}) = V(G), \qquad e \in E(\bar{G}) \iff e \notin E(G).
    \end{equation*}
\end{dfnbox}
\begin{thmbox}{Connectedness of Complement}{connectedComp}
    If $G$ is disconnected, then $\bar{G}$ is connected.
\end{thmbox}
\begin{dfnbox}{Distance, Eccentricity, Diameter}{distEDia}
    Let $G$ be a connected graph and let $u, v \in V(G)$. The {\color{red} \textbf{distance}} between $u$ and $v$, denoted by $d(u, v)$, is the length of the shortest path between $u$ and $v$. The {\color{red} \textbf{eccentricity}} of $u$ is defined to be
    \begin{equation*}
        e(u) = \max_{v \in V(G)}\{d(u, v)\}.
    \end{equation*}
    The {\color{red} \textbf{diameter}} of $G$ is defined by
    \begin{equation*}
        \mathrm{diam}(G) = \max_{u \in V(G)}\{e(u)\}.
    \end{equation*}
    The {\color{red} \textbf{radius}} of $G$ is defined by
    \begin{equation*}
        \mathrm{rad}(G) = \min_{u \in V(G)}\{e(u)\}.
    \end{equation*}
    A vertex $v$ is called a {\color{red} \textbf{central}} vertex if
    \begin{equation*}
        e(v) = \mathrm{rad}(v).
    \end{equation*}
    The subgraph induced by the set of central vertices of $G$ is known as the {\color{red} \textbf{centre}} of $G$.
\end{dfnbox}
\begin{thmbox}{Triangle Inequality}{triIneq}
    If $G$ is connected, then for any $u, v, w \in V(G)$,
    \begin{equation*}
        d(u, v) \leq d(u, w) + d(w, v).
    \end{equation*}
\end{thmbox}
\begin{thmbox}{Boundedness of Diameter}{boundedDiam}
    If $G$ is connected, then
    \begin{equation*}
        \mathrm{rad}(G) \leq \mathrm{diam}(G) \leq \mathrm{rad}(G).
    \end{equation*}
\end{thmbox}
\begin{dfnbox}{Cut-Vertex, Bridge}{cutNBridge}
    Let $G$ be a non-trivial connected graph. $v \in V(G)$ is called a {\color{red} \textbf{cut-vertex}} of $G$ if $\omega(G - v) > \omega(G)$. $e \in E(G)$ is called a {\color{red} \textbf{bridge}} of $G$ if $\omega(G - e) > \omega(G)$.
\end{dfnbox}

\section{Graphs and Matrices}
\begin{dfnbox}{Adjacency Matrix}{adMat}
    Let $G$ be a multigraph with $v(G) = n$, then the {\color{red} \textbf{adjacency matrix}} denoted by $\mathbfit{A}(G)$ is an $n \times n$ matrix such that $a_{ij}$ is the number of edges incident to both $v_i, v_j \in V(G)$.
\end{dfnbox}
\begin{dfnbox}{Incidence Matrix}{inMat}
    Let $G$ be a multigraph with $v(G) = n$ and $e(G) = m$, then the {\color{red} \textbf{incidence matrix}} denoted by $\mathbfit{M}(G)$ is an $n \times m$ matrix such that
    \begin{equation*}
        m_{ij} = \begin{cases}
            1, &\textrm{if } e_j \textrm{ is incident with } v_i \\
            0, &\textrm{otherwise}
        \end{cases}.
    \end{equation*}
\end{dfnbox}
\begin{probox}{}{}
    Let $G$ be a simple graph with adjacency matrix $\mathbfit{A}$, then the $(i, j)$-th entry of $\mathbfit{A}^k$ is the number of different $v_i$-$v_j$ walks of length $k$ in $G$.
\end{probox}
\begin{corbox}{}{}
    Let $G$ be a graph with $v(G) \geq 2$ and adjacency matrix $\mathbfit{A}$. Let
    \begin{equation*}
        \mathbfit{B} = \sum_{i = 1}^{n - 1}\mathbfit{A}^i,
    \end{equation*}
    then $G$ is connected if and only if $b_{ij} \neq 0$ for all $i \neq j$.
\end{corbox}

\chapter{Bipartite Graphs}
\section{Bipartite Graphs}
\begin{dfnbox}{Bipartite Graph}{bipartite}
    A graph $G$ is {\color{red} \textbf{bipartite}} if $V(G)$ can be partitioned into two disjointed subsets $V_1$ and $V_2$ such that every edge of $G$ joins a vertex in $V_1$ to a vertex in $V_2$.
\end{dfnbox}
Note that the size of a bipartite graph $G$ with partite sets $V_1$ and $V_2$ is just
\begin{equation*}
    e(G) = \sum_{x \in V_1}d_G(x) = \sum_{y \in V_2}d_G(y).
\end{equation*}
\begin{dfnbox}{Join}{join}
    Let $G_1$ and $G_2$ be two disjoint graphs of order $n_1$ and $n_2$ respectively. The {\color{red} \textbf{join}} of $G_1$ and $G_2$, deonoted by $G_1 + G_2$ is the graph such that
    \begin{align*}
        V(G_1 + G_2) & = V(G_1) \cup V(G_2) \\
        E(G_1 + G_2) & = E(G_1) \cup E(G_2) \cup \left\{uv \colon u \in V(G_1), v \in V(G_2)\right\}.
    \end{align*}
\end{dfnbox}
\begin{thmbox}{Complete Bipartite Graph}{completeBipartite}
    Let $0_p$ and $0_q$ be graphs of size $0$ and orders $p$ and $q$ respectively, then $K_{p, q} = 0_p + 0_q$ is a complete bipartite graph.
\end{thmbox}
\begin{thmbox}{Determination of Bipartite Graphs}{bipartiteIff}
    A graph is bipartite if and only if it contains no odd cycles.
\end{thmbox}

\section{Tree}
\begin{dfnbox}{Tree}{tree}
    A {\color{red} \textbf{tree}} is a {\color{red} \textbf{connected}} graph with {\color{red} \textbf{no cycles}}.
\end{dfnbox}
\begin{thmbox}{Equivalent Definitions for Trees}{equivDfnTree}
    Let $T$ be a connected graph of order $n$ and size $m$, then the following statements are equivalent:
    \begin{enumerate}
        \item $T$ is a tree;
        \item Every two vertices in $T$ are joined by a unique path;
        \item $m = n - 1$.
    \end{enumerate}
\end{thmbox}
\begin{dfnbox}{Forest}{forest}
    A {\color{red} \textbf{forest}} is a graph $G$ in which each component is a tree.
\end{dfnbox}
\begin{probox}{}{}
    Let $T$ be a tree with $\Delta(T) = k$. Let $n_i$ be the number of vertices in $T$ of degree $i$, then
    \begin{equation*}
        n_1 = 2 + \sum_{i = 1}^{k - 2}in_{i + 2}.
    \end{equation*}
\end{probox}
\end{document}