\documentclass[math, code]{amznotes}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
%\usepackage{yhmath}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{etoolbox}
\DeclareSymbolFont{yhlargesymbols}{OMX}{yhex}{m}{n} \DeclareMathAccent{\yhwidehat}{\mathord}{yhlargesymbols}{"62}

\usepackage{scalerel}[2014/03/10]
\usepackage{stackengine}

\renewcommand\widetilde[1]{\ThisStyle{%
  \setbox0=\hbox{$\SavedStyle#1$}%
  \stackengine{1pt-\LMpt}{$\SavedStyle#1$}{%
    \stretchto{\scaleto{\SavedStyle\mkern.2mu\sim}{.5467\wd0}}{.5\ht0}%
%    .2mu is the kern imbalance when clipping white space
%    .5467++++ is \ht/[kerned \wd] aspect ratio for \sim glyph
  }{O}{c}{F}{T}{S}%
}}
\makeatletter
\let\save@mathaccent\mathaccent
\newcommand*\if@single[3]{%
  \setbox0\hbox{${\mathaccent"0362{#1}}^H$}%
  \setbox2\hbox{${\mathaccent"0362{\kern0pt#1}}^H$}%
  \ifdim\ht0=\ht2 #3\else #2\fi
  }
%The bar will be moved to the right by a half of \macc@kerna, which is computed by amsmath:
\newcommand*\rel@kern[1]{\kern#1\dimexpr\macc@kerna}
%If there's a superscript following the bar, then no negative kern may follow the bar;
%an additional {} makes sure that the superscript is high enough in this case:
\newcommand*\widebar[1]{\@ifnextchar^{{\wide@bar{#1}{0}}}{\wide@bar{#1}{1}}}
%Use a separate algorithm for single symbols:
\newcommand*\wide@bar[2]{\if@single{#1}{\wide@bar@{#1}{#2}{1}}{\wide@bar@{#1}{#2}{2}}}
\newcommand*\wide@bar@[3]{%
  \begingroup
  \def\mathaccent##1##2{%
%Enable nesting of accents:
    \let\mathaccent\save@mathaccent
%If there's more than a single symbol, use the first character instead (see below):
    \if#32 \let\macc@nucleus\first@char \fi
%Determine the italic correction:
    \setbox\z@\hbox{$\macc@style{\macc@nucleus}_{}$}%
    \setbox\tw@\hbox{$\macc@style{\macc@nucleus}{}_{}$}%
    \dimen@\wd\tw@
    \advance\dimen@-\wd\z@
%Now \dimen@ is the italic correction of the symbol.
    \divide\dimen@ 3
    \@tempdima\wd\tw@
    \advance\@tempdima-\scriptspace
%Now \@tempdima is the width of the symbol.
    \divide\@tempdima 10
    \advance\dimen@-\@tempdima
%Now \dimen@ = (italic correction / 3) - (Breite / 10)
    \ifdim\dimen@>\z@ \dimen@0pt\fi
%The bar will be shortened in the case \dimen@<0 !
    \rel@kern{0.6}\kern-\dimen@
    \if#31
      \overline{\rel@kern{-0.6}\kern\dimen@\macc@nucleus\rel@kern{0.4}\kern\dimen@}%
      \advance\dimen@0.4\dimexpr\macc@kerna
%Place the combined final kern (-\dimen@) if it is >0 or if a superscript follows:
      \let\final@kern#2%
      \ifdim\dimen@<\z@ \let\final@kern1\fi
      \if\final@kern1 \kern-\dimen@\fi
    \else
      \overline{\rel@kern{-0.6}\kern\dimen@#1}%
    \fi
  }%
  \macc@depth\@ne
  \let\math@bgroup\@empty \let\math@egroup\macc@set@skewchar
  \mathsurround\z@ \frozen@everymath{\mathgroup\macc@group\relax}%
  \macc@set@skewchar\relax
  \let\mathaccentV\macc@nested@a
%The following initialises \macc@kerna and calls \mathaccent:
  \if#31
    \macc@nested@a\relax111{#1}%
  \else
%If the argument consists of more than one symbol, and if the first token is
%a letter, use that letter for the computations:
    \def\gobble@till@marker##1\endmarker{}%
    \futurelet\first@char\gobble@till@marker#1\endmarker
    \ifcat\noexpand\first@char A\else
      \def\first@char{}%
    \fi
    \macc@nested@a\relax111{\first@char}%
  \fi
  \endgroup
}
\makeatother

\graphicspath{ {./images/} }
\geometry{
    a4paper,
    headheight = 1.5cm
}

\patchcmd{\chapter}{\thispagestyle{plain}}
{\thispagestyle{fancy}}{}{}

\theoremstyle{remark}
\newtheorem*{claim}{Claim}
\newtheorem*{remark}{Remark}
\newtheorem{case}{Case}

\newcommand{\zero}{\mathbf{0}}
\newcommand{\one}{\mathbf{1}}
\newcommand{\I}{\mathbfit{I}}
\newcommand{\e}{\mathrm{e}}
\renewcommand{\d}{\mathrm{d}}
\newcommand{\im}{\mathrm{i}}
\newcommand{\map}[3]{#1: #2 \rightarrow #3} % Mapping
\newcommand{\image}[2]{#2\left[#1\right]} % Image
\newcommand{\preimage}[2]{#2\left[#1\right]^{-1}} % Pre-image
\newcommand{\eval}[3]{\left. #1\right\rvert_{#2 = #3}} % Evaluated at
%\newcommand\bigO[1]{\mathcal{O}\left(#1\right)}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathAlphabet{\mathcal}{OMS}{cmsy}{m}{n}

\begin{document}
\fancyhead[L]{
    Information and Coding Theory
}
\fancyhead[R]{
    Lecture Notes
}
\tableofcontents

\chapter{Probability}
\section{Probability Spaces}
In an elementary level, we have been viewing probability as the quotient between the number of desired outcomes and the number of all possible outcomes. This definition, though intuitive, is not very solid when it comes to an infinite sample space. In this introductory chapter, we would establish the theories of probability using a more modern and rigorous structure.
\begin{dfnbox}{Set Algebra}{setAlgebra}
    Let $X$ be a set. A {\color{red} \textbf{set algebra}} over $X$ is a family $\mathcal{F} \subseteq \mathcal{P}(X)$ such that 
    \begin{itemize}
        \item $X \backslash F \in \mathcal{F}$ for all $F \in \mathcal{F}$ (closed under complementation);
        \item $X \in \mathcal{F}$;
        \item $X_1 \cup X_2 \in \mathcal{F}$ for any $X_1, X_2 \in \mathcal{F}$ (closed under binary union).
    \end{itemize}
\end{dfnbox}
There are several immediate implications from the above definition. 

First, by closure under complementation, we know that an algebra over any set $X$ must contain the empty set. 

Second, by De Morgan's Law, one can easily check that if the first $2$ axioms hold, the closure under binary union is equivalent to 
\begin{itemize}
    \item $X_1 \cap X_2 \in \mathcal{F}$ for any $X_1, X_2 \in \mathcal{F}$;
    \item $\bigcup_{i = 1}^{n}X_i \in \mathcal{F}$ for any $X_1, X_2, \cdots, X_n \in \mathcal{F}$ for all $n \in \N$;
    \item $\bigcap_{i = 1}^{n}X_i \in \mathcal{F}$ for any $X_1, X_2, \cdots, X_n \in \mathcal{F}$ for all $n \in \N$.
\end{itemize}
$(X, \mathcal{F})$ is known as a \textit{field of sets}, where the elements of $X$ are called \textit{points} and those of $\mathcal{F}$, \textit{complexes} or \textit{admissible sets} of $X$.

In probability theory, what we are interested in is a special type of set algebras known as $\sigma$-\textit{algebras}.
\begin{dfnbox}{$\sigma$-Algebra}{sigmaAlgebra}
    A {\color{red} \textbf{$\sigma$-Algebra}} over a set $A$ is a non-empty set algebra over $A$ that is closed under countable union.
\end{dfnbox}
Of course, by the same argument as above, we known that any $\sigma$-algebra is closed under countable intersection as well.

Now, as we all know, we can take some set $\Omega$ as a \textit{sample space} and denote an \textit{event} by some subset of $\Omega$. Roughly speaking, we could now define the probability of an event $E \subseteq \Omega$ as the ratio between the sets' volumes. The remaining question now is: how do we define the volume of a set properly?
\begin{dfnbox}{Measure}{measure}
    Let $X$ be a set and $\Sigma$ be a $\sigma$-algebra over $X$. A {\color{red} \textbf{measure}} over $\Sigma$ is a function 
    \begin{equation*}
        \mu \colon \Sigma \to \R \cup \{-\infty, +\infty\}
    \end{equation*}
    such that 
    \begin{itemize}
        \item $\mu(E) \geq 0$ for all $E \in \Sigma$ (non-negativity);
        \item $\mu(\varnothing) = 0$;
        \item $\mu\left(\bigcup_{i = 1}^{\infty}E_i\right) = \sum_{i = 1}^{\infty}\mu(E_i)$ for any countable collection of pairwise disjoint elements of $\Sigma$ (countable additivity or $\sigma$-additivity).
    \end{itemize}
    The triple $(X, \Sigma, \mu)$ is known as a {\color{red} \textbf{measure space}} and the pair $(X, \Sigma)$, a {\color{red} \textbf{measurable space}}.
\end{dfnbox}
One thing to note here is that if at least one $E \in \Sigma$ has a finite measure, then $\mu(\varnothing) = 0$ is automatically guaranteed for obvious reasons.
\begin{dfnbox}{Probability Space}{probSpace}
    Let $\Omega$ be a sample space and $\mathcal{F}$ be a $\sigma$-algebra over $\Omega$. A {\color{red} \textbf{probability space}} is a measure space $(\Omega, \mathcal{F}, \mathbb{P})$ where $\mathbb{P} \colon \mathcal{F} \to [0, 1]$, known as a {\color{red} \textbf{probability measure}}, is such that $\mathbb{P}(\Omega) = 1$.
\end{dfnbox}
Obviously, the above definition immediately guarantees that 
\begin{enumerate}
    \item $\mathbb{P}(A^c) = 1 - \mathbb{P}(A)$;
    \item $\mathbb{P}(A) \leq \mathbb{P}(B)$ if $\mathbb{P}(A) \subseteq \mathbb{P}(A)$;
    \item $\mathbb{P}(A \cup B) \leq \mathbb{P}(A) + \mathbb{P}(B)$.
\end{enumerate}
The third result follows from a direct application of the principle of inclusion and exclusion. By induction, one can easily check that 
\begin{equation*}
    \mathbb{P}\left(\bigcup_{i = 1}^{n}E_i\right) \leq \sum_{i = 1}^{n}\mathbb{P}(E_i)
\end{equation*}
for any finitely many events. The following proposition extends this result to countable collections of events:
\begin{probox}{Union Bound of Countable Collections of Events}{unionBound}
    Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and $E_1, E_2, \cdots, E_n, \cdots \in \mathcal{F}$ is any countable sequence of events, then 
    \begin{equation*}
        \mathbb{P}\left(\bigcup_{i = 1}^{\infty}E_i\right) \leq \sum_{i = 1}^{\infty}\mathbb{P}(E_i).
    \end{equation*}
    \tcblower
    \begin{proof}
        Define $F_1 \coloneqq E_1$ and $F_k \coloneqq E_k \backslash \bigcup_{i = 1}^{k - 1}E_i$ for $k \geq 2$. Clearly, the $F_i$'s are pairwise disjoint. By Definition \ref{dfn:sigmaAlgebra}, the $F_i$'s are elements of $\mathcal{F}$. Note that $\mathbb{P}(F_i) \leq \mathbb{E_i}$ for all $i \in \N^+$, so 
        \begin{align*}
            \mathbb{P}\left(\bigcup_{i = 1}^{\infty}E_i\right) & = \mathbb{P}\left(\bigcup_{i = 1}^{\infty}F_i\right) \\
            & = \sum_{i = 1}^{\infty}\mathbb{P}(F_i) \\
            & \leq \sum_{i = 1}^{\infty}\mathbb{P}(E_i).
        \end{align*}
    \end{proof}
\end{probox}
Next, we will introduce the notion of \textit{random variables} formally. For this purpose, we first establish the notion of a \textit{Borel algebra}.
\begin{dfnbox}{Borel Algebra}{borelAlgebra}
    Let $X$ be a topological space. A {\color{red} \textbf{Borel set}} on $X$ is a set which can be formed via countable union, countable intersection and relative complementation of open sets in $X$. The smallest $\sigma$-algebra over $X$ containing all Borel sets on $X$ is known as the {\color{red} \textbf{Borel algebra}} over $X$.
\end{dfnbox}
Clearly, the Borel algebra over $X$ contains all open sets in $X$ according to the above axioms from Definition \ref{dfn:sigmaAlgebra}. This helps us define the following:
\begin{dfnbox}{Random Variable}{RV}
    Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and $(\mathcal{X}, \mathcal{B})$ be a measurable space where $\mathcal{B}$ is the Borel algebra over $\mathcal{X}$. A {\color{red} \textbf{random variable}} is a function $X \colon \Omega \to \mathcal{X}$ such that 
    \begin{equation*}
        \left\{\omega \in \Omega \colon X(\omega) \in B\right\} \in \mathcal{F} 
    \end{equation*}
    for all $B \in \mathcal{B}$.
\end{dfnbox}
\begin{notebox}
    \begin{remark}
        Rigorously, such a random variable $X$ is a \textit{measurable function} or \textit{measurable mapping} from $(\Omega, \mathcal{F})$ to $(\mathcal{X}, \mathcal{B})$.
    \end{remark}
\end{notebox}
The probability measure $\mathbb{P}$ thus induces a probability measure $P_X$ over $(\mathcal{X}, \mathcal{B})$.
\begin{dfnbox}{Distribution}{distribution}
    Let $X \colon \Omega \to \mathcal{X}$ be a random variable over the probability space $(\Omega, \mathcal{F}, \mathbb{P})$ and $\mathcal{B}$ be the Borel algebra over $\mathcal{X}$, the {\color{red} \textbf{distribution}} of $X$ is the probability measure $P_X$ on $(\mathcal{X}, \mathcal{B})$ given by 
    \begin{equation*}
        P_X(B) = \mathbb{P}\left(\left\{\omega \in \Omega \colon X(\omega) \in B\right\}\right).
    \end{equation*}
\end{dfnbox}
\begin{notebox}
    \begin{remark}
        Often times, we write $\mathrm{Pr}(X \in B) = P_X(B)$.
    \end{remark}
\end{notebox}
In the context of information theory, we mostly are concerned with real-valued random variables only.
\begin{dfnbox}{Real-Valued Random Variable}{RRV}
    Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, a {\color{red} \textbf{real-valued random variable}} over the space is a mapping $X \colon \Omega \to \R$ such that 
    \begin{equation*}
        \left\{\omega \in \Omega \colon X(\omega) \leq x\right\} \in \mathcal{F}
    \end{equation*}
    for all $x \in \R$.
\end{dfnbox}
Note that the Borel set over $\R$ is just the family of all open intervals. 

Clearly, if $X$ is a real-valued random variable, we have $\left\{\omega \in \Omega \colon X(\omega) > x\right\} \in \mathcal{F}$. Moreover, we claim that 
\begin{equation*}
    \left\{\omega \in \Omega \colon X(\omega) < x\right\} = \bigcup_{y < x}\left\{\omega \in \Omega \colon X(\omega) \leq y\right\}.
\end{equation*}
The proof is quite straightforward and is left to the reader as an exercise. By Definition \ref{dfn:sigmaAlgebra}, this means that 
\begin{equation*}
    \left\{\omega \in \Omega \colon X(\omega) < x\right\} \cup \left\{\omega \in \Omega \colon X(\omega) > x\right\} \in \mathcal{F}.
\end{equation*}
Therefore, $\left\{\omega \in \Omega \colon X(\omega) = x\right\} \in \mathcal{F}$. This argument justifies the probabilities $\mathrm{Pr}(X < x)$ and $\mathrm{Pr}(X = x)$. We give a special name to the range of a random variable in computer science.
\begin{dfnbox}{Alphabet}{alphabet}
    Let $X$ be a random variable, the range of $X$ is called an {\color{red} \textbf{alphabet}}, denoted as $\mathcal{X}$.
\end{dfnbox}
Recall that we have defined expectations for discrete and continuous random variables in elementary probability theory. In terms of measure theory, the two formulae can be unified as the Lebesgue integral
\begin{equation*}
    \mathbb{E}[X] = \int_{\Omega}\!X(\omega)\,\d\mathbb{P}(\omega).
\end{equation*}
Note that $\mathbb{E}[X]$ is a real number while $\mathbb{E}[X \mid Y]$ is a \textbf{random variable} formed as a function of $Y$. In a way, $Y$ partitions the sample space into regions where $\mathbb{E}[X \mid Y = y_i]$ gives the expectation of $X$ in the region induced by $Y = y_i$ for each $y_i \in \mathcal{Y}$. In general, the following result holds:
\begin{thmbox}{Law of Iterated Expectations}{iterExpectations}
    Let $X$ and $Y$ be random variables, then $\mathbb{E}\bigl[\mathbb{E}[X \mid Y]\bigr] = \mathbb{E}[X]$.
\end{thmbox}
The above formula can be interpreted as the fact that $\mathbb{E}[X \mid Y]$ is a best estimator for $X$.
\section{Markov Chains}
Recall that $2$ random variables $X$ and $Z$ are \textit{independent} if and only if $P_{X, Z}(x, z) = P_X(x)P_Z(z)$ or $P_{X \mid Z}(x \mid z) = P_X(x)$ for all $(x, z) \in \mathcal{X} \times \mathcal{Z}$. We will extend this definition with a third random variable.
\begin{dfnbox}{Markov Chain}{MarkovChain}
    Let $X, Y, Z$ be random variables. If 
    \begin{equation*}
        P_{X, Y, Z}(x, y, z) = P_X(x)P_{Y \mid X}(y \mid x)P_{Z \mid Y}(z \mid y)
    \end{equation*}
    for all $(x, y, z) \in \mathcal{X} \times \mathcal{Y} \times \mathcal{Z}$, then we say that $X, Y, Z$ forms a {\color{red} \textbf{Markov chain}} in this order, or that $X$ and $Z$ are conditionally independent on $Y$.
\end{dfnbox}
Recall also that the \textit{Bayes's Rule} states the following:
\begin{thmbox}{Bayes's Rule}{BayesRule}
    For any random variables $X$ and $Y$, 
    \begin{equation*}
        P_{X \mid Y}(x \mid y) = \frac{P_{Y \mid X}(y \mid x)P_X(x)}{\sum_{x' \in \mathcal{X}}P_{Y \mid X}(y \mid x')P_X(x')}.
    \end{equation*}
\end{thmbox}
Based on Theorem \ref{thm:BayesRule}, we have 
\begin{equation*}
    P_{X, Y}(x, y) = P_{X \mid Y}(x \mid y)P_Y(y) = P_X(x)P_{Y \mid X}(y \mid x).
\end{equation*}
By applying the formula repeatedly, we have 
\begin{align*}
    P_{X, Y, Z}(x, y, z) & = P_{X, Y}(x, y)P_{Z \mid X, Y}(z \mid x, y) \\
    & = P_X(x)P_{Y \mid X}(y \mid x)P_{Z \mid X, Y}(z \mid x, y).
\end{align*}
Therefore, a Markov chain simply states that the distribution of $Z$ is no longer dependent on $X$, but depends on $Y$ solely. Therefore, this allows us to remove one condition when applying Theorem \ref{thm:BayesRule}. Thus, it actually suffices to prove $P_{Z \mid X, Y} = P_{Z \mid Y}$ when proving that $X$-$Y$-$Z$ forms a Markov chain.  
 
We can denote a Markov chain by $X$-$Y$-$Z$. Intuitively, such a relationship should be symmetric.
\begin{probox}{Symmetricity of Markov Chains}{symmetricMarkovChains}
    If $X$-$Y$-$Z$ is a Markov chain, then $Z$-$Y$-$X$ is also a Markov chain.
    \tcblower
    \begin{proof}
        By Definition \ref{dfn:MarkovChain}, 
        \begin{align*}
            P_{X, Y, Z}(x, y, z) & = P_X(x)P_{Y \mid X}(y \mid x)P_{Z \mid Y}(z \mid y).
        \end{align*}
        By Theorem \ref{thm:BayesRule}, we have 
        \begin{align*}
            P_{X \mid Y}(x \mid y) & = \frac{P_X(x)P_{Y \mid X}(y \mid x)}{P_Y(y)} \\
            & = \frac{P_{X, Y, Z}(x, y, z)}{P_Y(y)P_{Z \mid Y}(z \mid y)} \\
            & = \frac{P_{X, Y, Z}(x, y, z)}{P_{Z, Y}(z, y)} \\
            & = P_{X \mid Z, Y}(x \mid z, y).
        \end{align*}
        Therefore, $Z$-$Y$-$X$ is a Markov chain.
    \end{proof}
\end{probox}
One obvious case where dependence exists between the random variables in a Markov chain is that one of the random variables is a function of another one.
\begin{probox}{Markov Chain Involving Functions of a Random Variable}{funcMarkovChain}
    Let $X$ and $Y$ be any random variables and $Z \coloneqq f(Y)$ for some function $f$, then $X$-$Y$-$Z$ is a Markov chain.
    \tcblower
    \begin{proof}
        Notice that 
        \begin{align*}
            P_{Z \mid X, Y}(z \mid x, y) & = P_{f(Y) \mid X, Y}(z \mid x, y) = \begin{cases}
                1 &\quad \textrm{if } z = f(y) \\
                0 &\quad \textrm{otherwise} 
            \end{cases}, \\
            P_{Z \mid Y}(z \mid y) & = P_{f(Y) \mid Y}(z \mid y) = \begin{cases}
                1 &\quad \textrm{if } z = f(y) \\
                0 &\quad \textrm{otherwise} 
            \end{cases}
        \end{align*}
        for all $(x, y, z) \in \mathcal{X} \times \mathcal{Y} \times \mathcal{Z}$. Therefore, $P_{Z \mid X, Y} = P_{Z \mid Y}$ and so $X$-$Y$-$Z$ forms a Markov chain.
    \end{proof}
\end{probox}
Note that if $X$ and $Z$ are independent, they are naturally conditionally independent given any $Y$. However, the inverse may not be true.
\begin{probox}{Conditional Independence Does Not Imply Independence}{condIndNotInd}
    There exists random variables $X, Y, Z$ such that $X$ and $Z$ are dependent but conditionally independent given $Y$.
    \tcblower
    \begin{proof}
        Let $N_1, N_2, N_3$ be pairwise independent random variables such that 
        \begin{equation*}
            \mathcal{N}_1 = \mathcal{N}_2 = \mathcal{N}_3 = \{0, 1\}.
        \end{equation*}
        Take $X = N_1 + N_2$, $Y = N_2$ and $Z = N_2 + N_3$. Clearly, $X$ and $Z$ are dependent, but 
        \begin{align*}
            P_{Z \mid X}(z \mid x) & = P_{N_2 + N_3 \mid N_1 + N_2}(z \mid x) \\
            & = P_{N_3 \mid N_1, N_2}(z - y \mid x - y, y) \\
            & = P_{N_2 + N_3 \mid N_1 + N_2, N_2}(z \mid x, y) \\
            & = P_{Z \mid X, Y}(z \mid x, y),
        \end{align*}
        which implies that $X$ and $Z$ are conditionally independent given $Y$.
    \end{proof}
\end{probox}
\section{Probability Bounds}
We use various bounds to make estimates and approximations for probability distributions. The first commonly used bound is \textit{Markov's Inequality}.
\begin{thmbox}{Markov's Inequality}{MarkovIneq}
    If $X$ is a non-negative random variable, then $\mathrm{Pr}(X \geq a) \leq \frac{\mathbb{E}[X]}{a}$ for all $a > 0$.
    \tcblower
    \begin{proof}
        It suffices to prove for the continuous case. Notice that 
        \begin{align*}
            \mathbb{E}[X] & = \int_{0}^{\infty}\!xf_X(x)\,\d x \\
            & \geq \int_{a}^{\infty}\!xf_X(x)\,\d x \\
            & \geq a\int_{0}^{\infty}\!f_X(x)\,\d x \\
            & = \mathrm{Pr}(X \geq a).
        \end{align*}
        Therefore, $\mathrm{Pr}(X \geq a) \leq \frac{\mathbb{E}[X]}{a}$.
    \end{proof}
\end{thmbox}
Note that the bound given by Markov's inequality is a rather loose bound. The following inequality proposes a better bound:
\begin{thmbox}{Chebyshev's Inequality}{ChebyshevIneq}
    For any real-valued random variable $X$ with finite variance, 
    \begin{equation*}
        \mathrm{Pr}\left(\abs{X - \mathbb{E}[X]} > a\sqrt{\mathrm{Var}(X)}\right) \leq \frac{1}{a^2}
    \end{equation*}
    for all $a > 0$.
    \tcblower
    \begin{proof}
        Define $g(X) \colon (X - \mathbb{E}[X])^2$, which is clearly non-negative. By Theorem \ref{thm:MarkovIneq}, we have 
        \begin{equation*}
            \mathrm{Pr}\bigl(g(X) > a^2\mathrm{Var}(X)\bigr) \leq \frac{\mathbb{E}[g(X)]}{a^2\mathrm{Var}(X)}.
        \end{equation*}
        Note that $\mathbb{E}[g(X)] = \mathrm{Var}(X)$, so 
        \begin{equation*}
            \mathrm{Pr}\left(\abs{X - \mathbb{E}[X]} > a\sqrt{\mathrm{Var}(X)}\right) = \mathrm{Pr}\bigl(g(X) > a^2\mathrm{Var}(X)\bigr) \leq \frac{1}{a^2}.
        \end{equation*}
    \end{proof}
\end{thmbox}
Finally, we state the following law of large numbers:
\begin{thmbox}{Weak Law of Large Numbers}{weakLawLargeNum}
    Let $X_1, X_2, \cdots, X_n$ be pairwise independent and identically distributed random variables with $\mathbb{E}[X_i] = \mu$ and $\mathrm{Var}(X_i) = \sigma^2 \in \R$ for every $i \in \N^+$. For every $\epsilon > 0$, we have 
    \begin{equation*}
        \lim_{n \to \infty}\mathrm{Pr}\left(\abs{\frac{1}{n}\sum_{i = 1}^nX_i - \mu} > \epsilon\right) = 0.
    \end{equation*}
    \tcblower
    \begin{proof}
        Note that $\mathbb{E}\left[\frac{1}{n}\sum_{i = 1}^nX_i\right] = \mu$ and that 
        \begin{equation*}
            \mathrm{Var}\left(\frac{1}{n}\sum_{i = 1}^nX_i\right) = \frac{\sum_{i = 1}^{n}\mathrm{Var}(X_i)}{n^2} = \frac{\sigma^2}{n}.
        \end{equation*}
        By Theorem \ref{thm:ChebyshevIneq}, we have 
        \begin{equation*}
            0 \leq \mathrm{Pr}\left(\abs{\frac{1}{n}\sum_{i = 1}^nX_i - \mu} > \epsilon\right) \leq \frac{\sigma^2}{n\epsilon^2}.
        \end{equation*}
        By Squeeze Theorem, this clearly implies that 
        \begin{equation*}
            \lim_{n \to \infty}\mathrm{Pr}\left(\abs{\frac{1}{n}\sum_{i = 1}^nX_i - \mu} > \epsilon\right) = 0.
        \end{equation*}
    \end{proof}
\end{thmbox}
Alternatively, we may phrase Theorem \ref{thm:weakLawLargeNum} as ``$\frac{1}{n}\sum_{i = 1}^nX_i$ converges to $\mu$ in probability''. When a sequence $\{S_n\}_{n = 1}^{\infty}$ converges to $b$ in probability, we write $S_n \xrightarrow{\mathrm{p}} b$. 
\begin{notebox}
    \begin{remark}
        Essentially, what Theorem \ref{thm:weakLawLargeNum} says is that when $n$ is large, the sample mean from $n$ measurements of the same data converges to the expectation of the distribution.
    \end{remark}
\end{notebox}
Under some mild conditions, this convergence occurs exponentially fast, i.e., the probability $\mathrm{Pr}\left(\abs{\frac{1}{n}\sum_{i = 1}^nX_i - \mu} > \epsilon\right)$ decreases at least as fast as $\exp\bigl(-ng(\epsilon)\bigr)$ for some real-valued function $g \colon \R^+ \to \R^+$. In terms of asymptotic analysis, we write this as 
\begin{equation*}
    \mathrm{Pr}\left(\abs{\frac{1}{n}\sum_{i = 1}^nX_i - \mu} > \epsilon\right) \leq \exp\bigl(-ng(\epsilon) + o(n)\bigr).
\end{equation*}
Equivalently, this means that there exists a function $g \colon \R \to \R$ with $g(\epsilon) > 0$ for every $\epsilon > 0$ such that 
\begin{equation*}
    \liminf_{n \to \infty}-\frac{1}{n}\log\mathrm{Pr}\left(\abs{\frac{1}{n}\sum_{i = 1}^nX_i - \mu} > \epsilon\right) \geq g(\epsilon) + o(1).
\end{equation*}
There is a strong version for the law, which shall be stated without proof:
\begin{thmbox}{Strong Law of Large Numbers}{strongLawLargeNum}
    Let $X_1, X_2, \cdots, X_n$ be pairwise independent and identically distributed random variables with $\mathbb{E}[X_i] = \mu$ and $\mathrm{Var}(X_i) = \sigma^2 \in \R$ for every $i \in \N^+$, then 
    \begin{equation*}
        \mathrm{Pr}\left(\lim_{n \to \infty}\frac{1}{n}\sum_{i = 1}^{n}X_i = \mu\right) = 1.
    \end{equation*}
\end{thmbox}
\section{Convexity}
Recall the following definition:
\begin{dfnbox}{Convex Function}{convexFunc}
    A function $f \colon \R^n \to \R$ is {\color{red} \textbf{convex}} if for any $\lambda \in [0, 1]$ and any $\mathbfit{x}, \mathbfit{y} \in \R^n$,
    \begin{equation*}
        f\bigl(\lambda\mathbfit{x} + (1 - \lambda)\mathbfit{y}\bigr) \leq \lambda f(\mathbfit{x}) + (1 - \lambda)f(\mathbfit{y}).
    \end{equation*}
\end{dfnbox}
From a graphical perspective, a convex function is an overestimate of all linear functions whose values are bounded above by it. The following proposition set this result in a rigorous context:
\begin{probox}{Convex Functions as Overestimates for Linear Functions}{convexFuncEstimate}
    Let $f \colon \R^n \to \R$ be a convex function and define 
    \begin{equation*}
        \mathcal{L} \coloneqq \left\{\ell \in \mathrm{Maps}\left(\R^n, \R\right) \colon \ell(\mathbfit{u}) = \mathbfit{a}^{\mathrm{T}} \cdot \mathbfit{u} + b \leq f(\mathbfit{u}) \textrm{ for all } \mathbfit{u} \in \R^n, \mathbfit{a} \in \R^n, b \in \R\right\}
    \end{equation*}
    to be the set of all linear functions bounded above by $f$, then for each $\mathbfit{x} \in \R^n$, 
    \begin{equation*}
        f(\mathbfit{x}) = \sup_{\ell \in \mathcal{L}}\ell(\mathbfit{x}).
    \end{equation*}
    \tcblower
    \begin{proof}
        It suffices to prove that for all $\mathbfit{x} \in \R^n$, there exists some linear function~$\ell \in \mathcal{L}$ such that $\ell(\mathbfit{x}) = f(\mathbfit{x})$. Take any $\mathbfit{h} \in \R^n$. Since $f$ is convex, we have 
        \begin{align*}
            2f(\mathbfit{x}) & = 2f\left(\frac{1}{2}(\mathbfit{x + h}) + \frac{1}{2}(\mathbfit{x - h})\right) \\
            & \leq f(\mathbfit{x + h}) + f(\mathbfit{x - h}).
        \end{align*}
        Therefore, we have
        \begin{equation*}
            L_1 = \lim_{\norm{\mathbfit{h}} \to 0}\frac{f(\mathbfit{x}) - f(\mathbfit{x - h})}{\norm{\mathbfit{h}}} \leq \lim_{\norm{\mathbfit{h}} \to 0}\frac{f(\mathbfit{x + h}) - f(\mathbfit{x})}{\norm{\mathbfit{h}}} = L_2.
        \end{equation*}
        Take some $a \in [L_1, L_2]$ and let $\ell(\mathbfit{y}) = a\norm{\mathbfit{y - x}} + f(\mathbfit{x})$. Observe that $\ell(\mathbfit{x}) = f(\mathbfit{x})$. Take $\mathbfit{h} = \mathbfit{y - x}$, then 
        \begin{align*}
            \ell(\mathbfit{y}) & = a\norm{\mathbfit{y - x}} + f(\mathbfit{x}) \\
            & \leq \frac{f(\mathbfit{x + h}) - f(\mathbfit{x})}{\norm{\mathbfit{h}}}\norm{\mathbfit{y - x}} + f(\mathbfit{x}) \\
            & = f(\mathbfit{x + h}) \\
            & = f(\mathbfit{y}).
        \end{align*} 
        Therefore, $\ell \in \mathcal{L}$ as desired.
    \end{proof}
\end{probox}
The following proposition gives a simple test for convexity in one-dimensional case, which is a special case of the Hessian matrix test:
\begin{probox}{Second Derivative Test for Convexity}{2ndDiffTest}
    If a real-valued function $f$ is twice-differentiable on $[a, b]$, then it is convex if and only if $f''(x) \geq 0$ for all $x \in (a, b)$.
\end{probox}
Convex functions produce the following interesting result regarding expectation:
\begin{thmbox}{Jensen's Inequality}{JensenIneq}
    Let $f$ be a convex function and $X$ be a random variable, then $\mathbb{E}[f(X)] \geq f(\mathbb{E}[X])$.
    \tcblower
    \begin{proof}
        Let $\mathcal{L}$ be the set of all linear functions bounded above by $f$. By Proposition \ref{pro:convexFuncEstimate}, we have 
        \begin{align*}
            \mathbb{E}[f(X)] & = \mathbb{E}\left[\sup_{\ell \in \mathcal{L}}\ell(X)\right] \\
            & \geq \sup_{\ell \in \mathcal{L}}\mathbb{E}[\ell(X)] \\
            & = \sup_{\ell \in \mathcal{L}}\ell(\mathbb{E}[X]) \\
            & = f(\mathbb{E}[X]).
        \end{align*}
    \end{proof}
\end{thmbox}
\begin{notebox}
    \begin{remark}
        If $f$ is strictly convex, the equality holds if and only if $X$ is constant.
    \end{remark}
\end{notebox}
\end{document}